#!/usr/bin/env python

#
#############################################################################
#
# airnefcmd.py - Wireless file transfer for PTP/MTP-equipped cameras (command-line app)
# Copyright (C) 2015, testcams.com
#
# This module is licensed under GPL v3: http://www.gnu.org/licenses/gpl-3.0.html
#
#############################################################################
#

from __future__ import print_function
from __future__ import division
import six
from six.moves import xrange
from six.moves import cPickle as pickle
import argparse
import mtpwifi
from mtpdef import *
import strutil
import struct
import time
import datetime
import sys
import os
import errno
import traceback
import platform
import socket
import hashlib
from dlinkedlist import *
from collections import namedtuple
from applog import *

#
# constants
#
AIRNEFCMD_APP_VERSION	= "1.00"
DEFAULT_MAX_KB_PER_GET_OBJECT_REQUEST				= 1024 		# 1MB - empirically tweaked to get max download performance from Nikon bodies (too large an xfer and Nikon bodies start intermittently dropping connections)
DEFAULT_MAX_KB_TO_BUFFER_FOR_GET_OBJECT_REQUESTS 	= 32768		# 32MB - max bytes we buffer before flushing what we have to disk

#
# custom errno from app
#
ERRNO_CAMERA_COMMUNICATION_FAILURE		= 4000
ERRNO_CAMERA_UNEXPECTED_RESP_CODE		= 4001
ERRNO_CAMERA_PROTOCOL_ERROR				= 4002
# place all errors for which app should bypass retry invocations here, between ERRNO_FIRST_CUSTOM_DONT_RETRY and ERRNO_LAST_CUSTOM_DONT_RETRY
ERRNO_FIRST_CUSTOM_DONT_RETRY			= 5000	# first custom errno that we trigger for which app should bypass any retry invocations
ERRNO_BAD_CMD_LINE_ARG					= 5000	# bad command line argument specified
ERRNO_FILE_EXISTS_USER_SPECIFIED_EXIT	= 5001	# a file exists that we were to write to and user configured app to exit when this occurs
ERRNO_DIFFERENT_CAMREA_DURING_RETRY		= 5002	# during a retry  invocation a different camera was discvered vs the original camera we found
ERRNO_NO_CAMERA_TRANSFER_LIST			= 5003  # no camera transfer list available and user configured app to exit if the list is not available
ERRNO_NO_CARD_MEDIA_AVIALABLE			= 5004  # second slot specified but camera only has 1 slot
ERRNO_MTP_OBJ_CACHE_VALIDATE_FAILED		= 5005	# we're performing a (debug) validation of object cache and found a mismatch
ERRNO_DOWNLOAD_FILE_OP_FAILED			= 5006	# create/append/write/close operation failed on file being downloaded
ERRNO_LAST_CUSTOM_DONT_RETRY			= 5099	# last custom errno that we trigger for which app should bypass any retry invocations

#
# structures
#
class GlobalVarsStruct:
	def __init__(self):
	
		self.isWin32 = None								# True if we're running on a Windows platform
		self.isFrozen = None							# True if we're running in a pyintaller frozen environment (ie, built as an executable)		
		self.args = None								# dictionary of command-line arguments (generated by argparse)
		self.appDir = None								# directory where script is located. this path is used to store all metadata files, in case script is run in different working directory
		self.appDataDir = None							# directory where we keep app metadata (self.appDir + "appdata")
		
		self.objfilter_dateStartEpoch = None			# user-specified starting date filter. any file earlier than this will be filtered.
		self.objfilter_dateEndEpoch = None				# user-specified ending date filter. any file later than this will be filtered.
		self.maxGetObjTransferSize = None				# max size of MTP_OP_GetPartialObject requests
		self.maxGetObjBufferSize = None					# max amount of download file data we buffer before flushing
	
		self.socketPrimary = None
		self.socketEvents = None
		
		self.storageId = None
		self.mtpDeviceInfo = None
		self.mtpStorageInfo = None
		self.cameraLocalMetadataPathAndRootName = None	# path+root name for all metadata files we associate with a specific model+serial number
		
		self.bReceivedTransferListFromCamera = False	# True if buildMtpObjects() found and retrieved a transfer list from the camera (ie, user picked photos to download on camera)
		self.bRetrievedMtpObjects = False				# True if buildMtpObjects() has successfully completed this session
		self.bDownloadedPartialMtpObjList	= False		# True if we only retreieved select MTP objects, such as when bReceivedTransferListFromCamera is True
			
		# download stats
		self.dlstat_countFilesSkippedDueToDownloadHistory = 0
		self.dlstat_countFilesSkippedDueToFileExistingLocally = 0
		self.dlstat_countFilesDownloaded = 0
		self.dlstat_totalBytesDownloaded = 0
		self.dlstat_totalDownloadTimeSecs = 0

		# exit cleanup tracking vars
		self.filesToDeleteOnAppExit = []
	
#
# global vars
#
g  = GlobalVarsStruct()


class PartialDownloadData():
	def __init__(self):
		self.bytesWritten = 0
		self.downloadTimeSecs = 0
		self.localFilenameWithoutPath = None
	def getBytesWritten(self):
		return self.bytesWritten
	def addBytesWritten(self, moreBytesWritten):
		self.bytesWritten += moreBytesWritten
	def getDownloadTimeSecs(self):
		return self.downloadTimeSecs
	def addDownloadTimeSecs(self, moreTimeSecs):
		self.downloadTimeSecs += moreTimeSecs
	def getLocalFilenameWithoutPath(self):
		return self.localFilenameWithoutPath
	def setLocalFilenameWithoutPath(self, localFilenameWithoutPath):
		self.localFilenameWithoutPath = localFilenameWithoutPath

#
# Main class to manage both individual MTP objects, including  files, directories, etc.., plus collections of these objects
#
class MtpObject(LinkedListObj):

	#
	# class variables
	#
	__MtpObjects_LL_CaptureDateSorted = LinkedList()	# link list of all MtpObject instances, sorted by capture date ([0] = oldest, [n-1]=newest)	
	__MtpObjects_ObjectHandleDict = {}					# dictionary of all objects, keyed by object handle 

	#
	# instance variables (documentation only since variables don't need to be declared in Python)
	# self.mtpObjectHandle:			Handle by which camera references this object
	# self.mtpObjectInfo: 			Structure containing information from MTP_OP_GetObjectInfo
	# self.captureDateEpoch:		self.mtpObjectInfo.captureDateStr converted to epoch time
	# self.bInTransferList:			TRUE if user selected this image for transfer in the camera
	# self.bDownloadedThisSession	TRUE if object has been downloaded successfully this session [for possible future retry logic, if implemented]
	#

	def __init__(self, mtpObjectHandle, mtpObjectInfo):
	
		# init some instance vars
		self.bInCameraTransferList = False
		self.bDownloadedThisSession = False
		self.partialDownloadData = None
		self.bytesWritten = 0
		self.downloadTimeSecs = 0

		# save handle and object info to instance vars
		self.mtpObjectHandle = mtpObjectHandle
		self.mtpObjectInfo = mtpObjectInfo

		if isDebugLog():
			applog_d("Creating MtpObject with the following mtpObjectInfo:\n" + str(self))
		
		# calculate instance vars that are based on mtpObjectInfo data
		if (self.mtpObjectInfo.captureDateStr != '19800000T000000'):
			self.captureDateEpoch = time.mktime( time.strptime(self.mtpObjectInfo.captureDateStr, "%Y%m%dT%H%M%S") )
		else:
			self.captureDateEpoch = 0
			
		# make sure this object hasn't already been inserted
		if self.mtpObjectHandle in MtpObject.__MtpObjects_ObjectHandleDict:
			raise AssertionError("MtpObject: Attempting to insert mtpObjectHandle that's already in dictionary. newObj:\n{:s}, existingObj:\n{:s}".format(
				self, MtpObject.__MtpObjects_ObjectHandleDict[self.mtpObjectHandle]))

		# insert into capture-date sorted linked list
		LinkedListObj.__init__(self, self.captureDateEpoch, MtpObject.__MtpObjects_LL_CaptureDateSorted)
			
		# insert into object handle dictionary, which is used for quick lookups by object handle
		MtpObject.__MtpObjects_ObjectHandleDict[self.mtpObjectHandle] = self
					
	def setInCameraTransferList(self):
		self.bInCameraTransferList = True
		
	def isInCameraTransferList(self):
		return self.bInCameraTransferList
		
	def setAsDownloadedThisSession(self):
		self.bDownloadedThisSession = True
		
	def wasDownloadedThisSession(self):
		return self.bDownloadedThisSession
		
	def isPartialDownload(self):
		return self.partialDownloadData != None
		
	def partialDownloadObj(self):
		if self.partialDownloadData:
			return self.partialDownloadData
		self.partialDownloadData = PartialDownloadData()
		return self.partialDownloadData
		
	def releasePartialDownloadObj(self):
		if self.partialDownloadData:
			self.partialDownloadData = None
			
	def getImmediateDirectory(self): # gets immediate camera directory that this object is in. ex: "100NC1J4"
		objHandleDirectory = self.mtpObjectInfo.parentObject
		if objHandleDirectory not in MtpObject.__MtpObjects_ObjectHandleDict:
			return ""			
		dirObject = MtpObject.__MtpObjects_ObjectHandleDict[objHandleDirectory]
		return dirObject.mtpObjectInfo.filename		
							
	def genFullPathStr(self): # builds full path string to this object on camera, including filename itself. Ex: "DCIM\100NC1J4\DSC_2266.NEF"
		# full path built by walking up the parent object tree for this object, prepending the directory of each parent we find
		pathStr = self.mtpObjectInfo.filename
		objHandleAncestorDirectory = self.mtpObjectInfo.parentObject
		loopIterationCounter_EndlessLoopProtectionFromCorruptList = 0
		while (objHandleAncestorDirectory != 0):
			if objHandleAncestorDirectory not in MtpObject.__MtpObjects_ObjectHandleDict:
				# couldn't find next folder up. this is expected for g.bDownloadedPartialMtpObjList, otherwise it indicates a problem
				if not g.bDownloadedPartialMtpObjList:
					applog_d("Warning: Unable to locate parent object for {:s}".format(self.mtpObjectInfo.filename))
				return pathStr
			dirObject = MtpObject.__MtpObjects_ObjectHandleDict[objHandleAncestorDirectory]
			pathStr = dirObject.mtpObjectInfo.filename + "\\" + pathStr
			objHandleAncestorDirectory = dirObject.mtpObjectInfo.parentObject
			loopIterationCounter_EndlessLoopProtectionFromCorruptList += 1
			if loopIterationCounter_EndlessLoopProtectionFromCorruptList >= 512:	
				# 512 is arbitrary. wouldn't expect cameras to have more than one or two directory levels
				raise AssertionError("Endless loop detected while building directory chain for {:s}. Local list is corrupt".format(pathStr))
			
		return pathStr
							
	@classmethod
	def getCount(cls):	# returns count of objects
		return MtpObject.__MtpObjects_LL_CaptureDateSorted.count()
		
	@classmethod
	def getOldest(cls):	# returns oldest object in age collection
		if MtpObject.__MtpObjects_LL_CaptureDateSorted.count():		# if list is not empty
			return MtpObject.__MtpObjects_LL_CaptureDateSorted.head()
		else:
			return None
							
	@classmethod
	def getNewest(cls):	# returns newest object in age collection
		if MtpObject.__MtpObjects_LL_CaptureDateSorted.count():		# if list is not empty
			return MtpObject.__MtpObjects_LL_CaptureDateSorted.tail()
		else:
			return None
		
	def getNewer(self):	# returns next newer object
		return self.llNext()
			
	def getOlder(self):	# returns next older object
		return self.llPrev()

	@classmethod
	def getByMtpObjectHandle(cls, mtpObjectHandle):
		if mtpObjectHandle in MtpObject.__MtpObjects_ObjectHandleDict:
			return MtpObject.__MtpObjects_ObjectHandleDict[mtpObjectHandle]
		else:
			return None
			
	def __str__(self):	# generates string description of object
		s =  "MtpObject instance = 0x{:08x}\n".format(id(self))
		s += "  mtpObjectHandle = 0x{:08x}\n".format(self.mtpObjectHandle)
		s += "  --- mptObjectInfo ---\n"		
		s += "    storageId          = " + getMtpStorageIdDesc(self.mtpObjectInfo.storageId) + "\n"
		s += "    objectFormat       = " + getMtpObjFormatDesc(self.mtpObjectInfo.objectFormat) + "\n"
		s += "    protectionStatus   = " + strutil.hexShort(self.mtpObjectInfo.protectionStatus) + "\n"
		s += "    compressedSize     = " + strutil.hexWord(self.mtpObjectInfo.objectCompressedSize) + "\n"
		s += "    thumbFormat        = " + getMtpObjFormatDesc(self.mtpObjectInfo.thumbFormat) + "\n"
		s += "    thumbCompressedSize= " + strutil.hexWord(self.mtpObjectInfo.thumbCompressedSize) + "\n"
		s += "    thumbPixDimensions = " + str(self.mtpObjectInfo.thumbPixWidth) + "x" + str(self.mtpObjectInfo.thumbPixHeight) + "\n"
		s += "    imagePixDimensions = " + str(self.mtpObjectInfo.imagePixWidth) + "x" + str(self.mtpObjectInfo.imagePixHeight) + "\n"
		s += "    imageBitDepth      = " + str(self.mtpObjectInfo.imageBitDepth) + "\n"
		s += "    parentObject       = " + strutil.hexWord(self.mtpObjectInfo.parentObject) + "\n"
		s += "    associationType    = " + getObjAssocDesc(self.mtpObjectInfo.associationType) + "\n"
		s += "    associationDesc    = " + strutil.hexWord(self.mtpObjectInfo.associationDesc) + "\n"
		s += "    sequenceNumber     = " + strutil.hexWord(self.mtpObjectInfo.sequenceNumber) + "\n"
		s += "    filename           = " + self.genFullPathStr() + "\n"
		s += "    captureDateSt      = " + self.mtpObjectInfo.captureDateStr + "\n"
		s += "    modificationDateStr= " + self.mtpObjectInfo.modificationDateStr
		return s

#
# verifies user is running version a modern-enough version of python for this app
#		
def verifyPythonVersion():
	if sys.version_info.major == 2:
		if sys.version_info.minor < 7:
			applog_i("Warning: You are running a Python 2.x version older than app was tested with.")
			applog_i("Version running is {:d}.{:d}.{:d}, app was tested on 2.7.x".format(sys.version_info.major, sys.version_info.minor, sys.version_info.micro))
	elif sys.version_info.major == 3:
		if sys.version_info.minor < 4:
			applog_i("Warning: You are running a Python 3.x version older than app was tested with.")
			applog_i("Version running is {:d}.{:d}.{:d}, app was tested on 3.4.x".format(sys.version_info.major, sys.version_info.minor, sys.version_info.micro))

			
#
# sets app-level globals related to the platform we're running under and
# creates path to app directories, creating them if necessary
#			
def establishAppEnvironment():

	g.isWin32 = (platform.system() == 'Windows')
	g.isFrozen = (getattr(sys, 'frozen', False))

	#
	# determine the directory our script resides in, in case the
	# user is executing from a different working directory.
	#
	g.appDir = os.path.dirname(os.path.realpath(sys.argv[0]))

	#
	# determine directory for our APPDATA, which contains log
	# and configuration files. For Win32 if we're frozen this
	# goes in the dedicated OS area for application data files
	#
	if g.isWin32 and g.isFrozen and os.getenv('LOCALAPPDATA'):
		localAppDataAirnef = os.path.join(os.getenv('LOCALAPPDATA'), "airnef\\appdata") # typically C:\Users\<username>\AppData\Local\airnef\appdata
		if not os.path.exists(localAppDataAirnef):
			os.makedirs(localAppDataAirnef)
		g.appDataDir = localAppDataAirnef
	else:
		g.appDataDir = os.path.join(g.appDir, "appdata")
	
	# create our app-specific subdirectories if necessary
	if not os.path.exists(g.appDataDir):
		os.makedirs(g.appDataDir)

		
#
# transltes a date or date+time string from the user into an
# epoch time (ie, time in seconds).
#
def translateDateCmdLineArgToEpoch(cmdArgDesc, isInclusiveEndDate=False):
	userDateTimeStr = g.args[cmdArgDesc]
	if userDateTimeStr == None:
		# user did not specify arg
		return None
	if userDateTimeStr.find(":") != -1:
		# user specified date and time
		strptimeTranslationStr = "%m/%d/%y %H:%M:%S"
		bOnlyDateSpecified = False
	else:
		# user only specified time
		strptimeTranslationStr = "%m/%d/%y"
		bOnlyDateSpecified = True		
	try:
		strptimeResult = time.strptime(userDateTimeStr, strptimeTranslationStr)
	except ValueError as e:
		applog_e("Date specified for \"--{:s}\" is \"{:s}\", which is formatted incorrectly or has an invalid date/time. It must be formatted as mm/dd/yy or mm/dd/yy hh:mm:ss (including leading zeros) and be a valid date/time.".\
			format(cmdArgDesc, userDateTimeStr))
		sys.exit(ERRNO_BAD_CMD_LINE_ARG)
	timeEpoch = time.mktime(strptimeResult)
	if bOnlyDateSpecified and isInclusiveEndDate:
		timeEpoch += (23*60*60) + (59*60) + 59	# make end date inclusive by adding 23 hours, 59 minutes, 59 seconds to epoch time
	return timeEpoch


#
# processCmdLine - Processes command line arguments
#
class ArgumentParserError(Exception): pass # from http://stackoverflow.com/questions/14728376/i-want-python-argparse-to-throw-an-exception-rather-than-usage
class ArgumentParserWithException(argparse.ArgumentParser):
    def error(self, message):
        raise ArgumentParserError(message)

def processCmdLine():
	parser = ArgumentParserWithException(fromfile_prefix_chars='@',\
		formatter_class=argparse.RawDescriptionHelpFormatter,
		description='Wifi image transfer utility for Nikon cameras (airnef@hotmail.com)',\
		epilog="Options can also be specified from a file. Use @<filename>. Each word in the\nfile must be on its own line.\n\n"\
			"Command-Line Examples:\n"\
			"  %(prog)s --extlist NEF MOV (download only raw images and MOV files)\n"\
			"  %(prog)s --downloadhistory ignore (dont skip files previously downloaded)")
	parser.add_argument('--ipaddress', type=str, help='IP address of camera. Default is "%(default)s"', default='192.168.1.1', metavar="addr", required=False)			
	parser.add_argument('--action', type=str, choices=['getfiles', 'getsmallthumbs', 'getlargethumbs', 'listfiles'], help='Program action. Default is "%(default)s"', default='getfiles', required=False)
	parser.add_argument('--extlist', help='Type of image/file(s) to download. Ex: \"--extlist NEF\". Multiple extensions can be specified. Use \"<NOEXT>\" to include files that don\'t have extensions. Default is to download all file types', default=['<ALL>'], nargs='+', metavar="file_extension", required=False)
	parser.add_argument('--startdate', help='Only include image/file(s) captured on or later than date. Date-only Ex: --startdate 12/05/14 Date+Time Ex: --startdate \"12/05/14 15:30:00\"', metavar="date", required=False)
	parser.add_argument('--enddate', help='Only include image/file(s) captured on or earlier than date or date+time. Date without a specified time is inclusive, so for example --enddate 06/12/14 is interpreted as 06/12/14 23:59:59', metavar="date", required=False)
	parser.add_argument('--outputdir', type=str, help='Directory to store image/file(s) to.  Default is current directory. If path contains any spaces enclose it in double quotes and make sure there is no ending backslash. Example: --outputdir \"c:\My Documents\"', default='.\\', metavar="path", required=False)
	parser.add_argument('--ifexists', type=str, choices=['uniquename', 'skip', 'overwrite', 'prompt', 'exit'], help='Action to take if file with same name already exists. Default is "%(default)s"', default='uniquename', required=False)
	parser.add_argument('--downloadhistory', type=str, choices=['skipfiles', 'ignore', 'clear' ], help='\'skipfiles\' means that files in history (ie, previously downloaded) will be skipped and not downloaded. Default is "%(default)s"', default='skipfiles', required=False)
	parser.add_argument('--onlyfolders', help='Only include image/file(s) existing in specified camera folders.. Ex: \"--onlyfolders 100D7200 101D7200\". Default is to include all folders', default=None, nargs='+', metavar="camera_folder", required=False)
	parser.add_argument('--excludefolders', help='Exclude image/file(s) existing in specified camera folders.. Ex: \"--excludefolders 103D7200\". Default is no exclusions.', default=None, nargs='+', metavar="camera_folder", required=False)		
	parser.add_argument('--camerafolderinoutputdir', type=str, choices=['no', 'yes'], help='Include camera folder in output path, creating subdirectory if necessary. Default is "%(default)s"', default='no', required=False)
	parser.add_argument('--transferorder', type=str, choices=['oldestfirst', 'newestfirst'], help='Transfer oldest or newest files first. Default is "%(default)s"', default='oldestfirst', required=False)
	parser.add_argument('--slot', type=str, help='Card slot on camera to read from. Default is "%(default)s", which means first populated slot', choices=['firstfound', 'first', 'second'], default='firstfound', required=False)
	parser.add_argument('--cameratransferlist', type=str, choices=['useifavail', 'exitifnotavail', 'ignore'], help='Decide how to handle images selected on camera. Default is "%(default)s"', default='useifavail', required=False)
	parser.add_argument('--logginglevel', type=str, choices=['normal', 'verbose', 'debug' ], help='Sets how much information is saved to the result log. Default is "%(default)s"', default='normal', required=False)
	# hidden args (because they wont be used often and will complicate users learning the command line - they are documented online)
	parser.add_argument('--connecttimeout', help=argparse.SUPPRESS, type=int, default=10, required=False)
	parser.add_argument('--socketreadwritetimeout', help=argparse.SUPPRESS, type=int, default=5, required=False)
	parser.add_argument('--retrycount', help=argparse.SUPPRESS, type=int, default=sys.maxsize, required=False)
	parser.add_argument('--retrydelaysecs', help=argparse.SUPPRESS, type=int, default=5, required=False)
	parser.add_argument('--printstackframes', help=argparse.SUPPRESS, type=str, choices=['no', 'yes'], default='no', required=False)
	parser.add_argument('--mtpobjcache', type=str, choices=['enabled', 'writeonly', 'readonly', 'verify', 'disabled'], help=argparse.SUPPRESS, default='enabled', required=False)	
	parser.add_argument('--mtpobjcache_maxagemins', help=argparse.SUPPRESS, type=int, default=0, required=False) # default is 0=indefinite (never invalidate based on age)
	parser.add_argument('--maxgetobjtransfersizekb', help=argparse.SUPPRESS, type=int, default=DEFAULT_MAX_KB_PER_GET_OBJECT_REQUEST, required=False)	
	parser.add_argument('--maxgetobjbuffersizekb', help=argparse.SUPPRESS, type=int, default=DEFAULT_MAX_KB_TO_BUFFER_FOR_GET_OBJECT_REQUESTS, required=False)

	#
	# if there is a default arguments file present, add it to the argument list so that parse_args() will process it
	#
	defaultArgFilename = os.path.join(g.appDir, "airnefcmd-defaultopts")
	if os.path.exists(defaultArgFilename):
		sys.argv.insert(1, "@" + defaultArgFilename) # insert as first arg (past script name), so that the options in the file can still be overriden by user-entered cmd line options
	
	# perform the argparse
	try:
		args = vars(parser.parse_args())
	except ArgumentParserError as e:
		applog_e("Command line error: " + str(e))
		sys.exit(ERRNO_BAD_CMD_LINE_ARG)
	
	
	# set our global var to the processed argument list	and log them
	g.args = args

	# process any args that need translation/conversion
	g.objfilter_dateStartEpoch = translateDateCmdLineArgToEpoch('startdate')
	g.objfilter_dateEndEpoch = translateDateCmdLineArgToEpoch('enddate', isInclusiveEndDate=True)
	g.maxGetObjTransferSize = g.args['maxgetobjtransfersizekb'] * 1024
	g.maxGetObjBufferSize = g.args['maxgetobjbuffersizekb'] * 1024	

	# process any args that require action now
	if g.args['logginglevel'] == 'normal':
		# we've already set to this default
		pass
	elif g.args['logginglevel'] == 'verbose':
		applog_set_loggingFlags(APPLOGF_LEVEL_INFORMATIONAL | APPLOGF_LEVEL_ERROR | APPLOGF_LEVEL_WARNING | APPLOGF_LEVEL_VERBOSE)
	elif g.args['logginglevel'] == 'debug':
		applog_set_loggingFlags(APPLOGF_LEVEL_INFORMATIONAL | APPLOGF_LEVEL_ERROR | APPLOGF_LEVEL_WARNING | APPLOGF_LEVEL_VERBOSE | APPLOGF_LEVEL_DEBUG)

	# log the cmd line arguments
	applog_d("Orig cmd line: {:s}".format(str(sys.argv)))
	applog_d("Processed cmd line: {:s}".format(str(g.args)))

		
#
# Converts counted utf-16 MTP string to unicode string
#
def mtpCountedUtf16ToPythonUnicodeStr(data):
	# format of string: first byte has character length of string inlcuding NULL (# bytes / 2)
	(utf16CharLenIncludingNull,) = struct.unpack('<B', data[0:1])
	if utf16CharLenIncludingNull ==  0:
		# count byte of zero indicates no string.
		return "", 1
	
	utf16ByteLenIncludingNull = utf16CharLenIncludingNull*2
	unicodeStr = six.text_type(data[1:1+utf16ByteLenIncludingNull-2], 'utf-16')
	
	# some Nikon strings have trailing NULLs for padding - remove them
	for charPos in reversed(xrange(len(unicodeStr))):
		if unicodeStr[charPos] != '\x00':
			break;
	unicodeStr = unicodeStr[0:charPos+1]	# ok if original string was null-only string
	
	return unicodeStr, 1+utf16ByteLenIncludingNull	# 1+ for first byte containing character length


#
# Removes specified leading characters from string
#
def removeLeadingCharsFromStr(str, charsToRemoveSet):
	for charPos in xrange(len(str)):
		if str[charPos] not in charsToRemoveSet:
			break;
	return str[charPos:]


#
# Converts a raw MTP-obtained counted array of values into a list format
# of string: first word has count of entries, followed by array of entries,
# each of which is 'elementSizeInBytes' in size. Returns (list, bytesConsumedFromData),
# where 'list' is the list of entries and 'bytesConsumedFromData' is the number of
# bytes used from 'data' to generate the list
#
def parseMtpCountedList(data, elementSizeInBytes):

	elementSizeToUnpackStr = { 1 : 'B', 2 : 'H', 4 : 'I' }

	theList = list()
	(countEntries,) = struct.unpack('<I', data[0:4])
	offset = 4
	for entryIndex in xrange(countEntries):
		(entry,) = struct.unpack('<' + elementSizeToUnpackStr[elementSizeInBytes], data[offset:offset+elementSizeInBytes])
		offset += elementSizeInBytes
		theList.append(entry)
	return theList, countEntries*elementSizeInBytes + 4		# +4 to include count field itself
def parseMtpCountedWordList(data):
	return parseMtpCountedList(data, 4)
def parseMtpCountedHalfwordList(data):
	return parseMtpCountedList(data, 2)


#
# parses the raw data from MTP_OP_GetStorageIDs into a MptStorageIds tuple
#	
def parseMptStorageIds(data):
	(storageIdsList,bytesConsumed) = parseMtpCountedWordList(data)
	return MptStorageIdsTuple(storageIdsList)


#
# parses the raw data from MTP_OP_GetStorageInfo into a MtpStorageInfo tuple
#		
def parseMtpStorageInfo(data):
	(storageType,fileSystemType,accessCapability,maxCapacityBytes,freeSpaceBytes,freeSpaceInImages,storageDescription) = struct.unpack('<HHHQQIB', data[0:27])
	(volumeLabel,byteLen) = mtpCountedUtf16ToPythonUnicodeStr(data[27:])	
	return MtpStorageInfoTuple(storageType, fileSystemType, accessCapability, maxCapacityBytes,
						freeSpaceBytes, freeSpaceInImages, storageDescription, volumeLabel)						
	

#
# parses the raw data from MTP_OP_GetDeviceInfo into a MtpDeviceInfo tuple
#			
def parseMtpDeviceInfo(data):

	(standardVersion, vendorExtensionID, vendorExtensionVersion) = struct.unpack('<HIH', data[0:8])
	
	offset = 8
	(vendorExtensionDescStr,bytesConsumed) = mtpCountedUtf16ToPythonUnicodeStr(data[offset:])
	offset += bytesConsumed
	offset += 2			# skip 'FunctionalMode' field
	
	(operationsSupportedList,bytesConsumed) = parseMtpCountedHalfwordList(data[offset:])
	offset += bytesConsumed
	
	(eventsSupportedList,bytesConsumed) = parseMtpCountedHalfwordList(data[offset:])
	offset += bytesConsumed
	
	(devicePropertiesSupportedList,bytesConsumed) = parseMtpCountedHalfwordList(data[offset:])
	offset += bytesConsumed
	
	(captureFormatsSupportedList,bytesConsumed) = parseMtpCountedHalfwordList(data[offset:])
	offset += bytesConsumed
	
	(imageFormatsSupportedList,bytesConsumed) = parseMtpCountedHalfwordList(data[offset:])
	offset += bytesConsumed

	(manufacturerStr,byteLen) = mtpCountedUtf16ToPythonUnicodeStr(data[offset:])
	offset += byteLen
	(modelStr,byteLen) = mtpCountedUtf16ToPythonUnicodeStr(data[offset:])
	offset += byteLen
	(deviceVersionStr,byteLen) = mtpCountedUtf16ToPythonUnicodeStr(data[offset:])
	offset += byteLen
	(serialNumberStr,byteLen) = mtpCountedUtf16ToPythonUnicodeStr(data[offset:])
	serialNumberStr = removeLeadingCharsFromStr(serialNumberStr, {' ', '0'}) # remove leading spaces/zeros from serial number

	return MtpDeviceInfoTuple(	standardVersion, vendorExtensionID, vendorExtensionVersion, vendorExtensionDescStr,\
						set(operationsSupportedList), set(eventsSupportedList), set(devicePropertiesSupportedList), \
						set(captureFormatsSupportedList), set(imageFormatsSupportedList), manufacturerStr, \
						modelStr, deviceVersionStr, serialNumberStr)	


#
# parses the raw data from MTP_OP_GetObjectInfo into a MtpObjectInfo tuple
#									
def parseMtpObjectInfo(data):

	(storageId, objectFormat, protectionStatus) = struct.unpack('<IHH', data[0:8])
	(objectCompressedSize, thumbFormat, thumbCompressedSize) = struct.unpack('<IHI', data[8:18])
	(thumbPixWidth, thumbPixHeight, imagePixWidth, imagePixHeight) = struct.unpack('<IIII', data[18:34])			
	(imageBitDepth, parentObject, associationType) = struct.unpack('<IIH', data[34:44])
	(associationDesc, sequenceNumber) = struct.unpack('<II', data[44:52])
				
	offset = 52
	(filename, bytesConsumed) = mtpCountedUtf16ToPythonUnicodeStr(data[offset:])
	offset = offset + bytesConsumed			
	(captureDateStr, bytesConsumed) = mtpCountedUtf16ToPythonUnicodeStr(data[offset:])
	captureDateStr = captureDateStr[:15] # Canon adds a ".0"... to the capture date/time - trim that off
	offset = offset + bytesConsumed
	(modificationDateStr, bytesConsumed) =  mtpCountedUtf16ToPythonUnicodeStr(data[offset:])
	modificationDateStr = modificationDateStr[:15] # Canon adds a ".0"... to the modification date/time - trim that off

	return MtpObjectInfoTuple(	storageId, objectFormat, protectionStatus, \
						objectCompressedSize, thumbFormat, thumbCompressedSize, \
						thumbPixWidth, thumbPixHeight, imagePixWidth, imagePixHeight, \
						imageBitDepth, parentObject, associationType, \
						associationDesc, sequenceNumber, filename, \
						captureDateStr, modificationDateStr)
						

#
# closes TCP/IP connection sockets to camera's MTP interface
#
def closeSockets():	
	if g.socketPrimary:
		g.socketPrimary.close()
		g.socketPrimary = None
	if g.socketEvents:
		g.socketEvents.close()
		g.socketEvents = None
		

#
# starts an MTP session with the camera, including opening the TCP/IP
# socket connections, sending the MTP-WiFi host introduction primitive,
# and performing an MTP_OP_OpenSession
#		
def startMtpSession():

	#
	# open TCP/IP socket connection to camera
	#
	g.socketPrimary = mtpwifi.openConnection(g.args['ipaddress'], True, g.args['connecttimeout'], g.args['socketreadwritetimeout'])

	#
	# get session ID
	#
	data = mtpwifi.sendHostIntroduction(g.socketPrimary)
	g.sessionId = data[:4]
	applog_d("Session ID = {:s}".format(strutil.hexWordFromData(g.sessionId)))
		
	#
	# open secondary socket for events
	#
	g.socketEvents = mtpwifi.openConnection(g.args['ipaddress'], False, g.args['connecttimeout'], g.args['socketreadwritetimeout'])
	data = mtpwifi.sendInitEvents(g.socketEvents, g.sessionId)
	
	#
	# for unknown reasons, MTP_OP_OpenSession will fail if we don't delay
	# by at least 1 second after opening sockets and event session
	#
	applog_d(">> Delaying for 1 second to avoid open session issue")
	time.sleep(1)

	#
	# open session
	#
	mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_OpenSession, g.sessionId)


#
# sends the high-level MTP_OP_CloseSession primitive to close the session 
# with the camera
#	
def endMtpSession():

	#
	# close session
	#
	mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_CloseSession)
	

#
# performs a MTP_OP_GetDeviceInfo and saves the information into g.mtpDeviceInfo
#
def getMtpDeviceInfo():
	mtpTcpCmdResult = mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_GetDeviceInfo)	
	mtpDeviceInfo = parseMtpDeviceInfo(mtpTcpCmdResult.dataReceived)
	if g.mtpDeviceInfo:
		# this is a retry invocation. make sure we're talking with the same camera as before
		if mtpDeviceInfo != g.mtpDeviceInfo:
			applog_e("Discovered different camera during retry invocation. Orig camera was Model \"{:s}\", S/N \":{:s}\", New camera is \"{:s}\", S/N \":{:s}\"".format(\
				g.mtpDeviceInfo.modelStr, g.mtpDeviceInfo.serialNumberStr, mtpDeviceInfo.modelStr, mtpDeviceInfo.serialNumberStr))
			sys.exit(ERRNO_DIFFERENT_CAMREA_DURING_RETRY)
	
	g.mtpDeviceInfo = mtpDeviceInfo
	applog_d(g.mtpDeviceInfo)

	#
	# build path (dir + rootfilename) that will serve as the template for all metadata
	# files we create and store locally. this name needs to be unique to the camera
	# attached and locatable on future invocations, so we use a combination of the camera
	# model and serial number
	#	
	g.cameraLocalMetadataPathAndRootName = os.path.join(g.appDataDir, "{:s}-SN{:s}".format(g.mtpDeviceInfo.modelStr, g.mtpDeviceInfo.serialNumberStr))
	
	applog_i("Camera Model \"{:s}\", S/N \"{:s}\"".format(g.mtpDeviceInfo.modelStr, g.mtpDeviceInfo.serialNumberStr))


#
# selects the storage ID on the camera (ie, media card/slot) to use for this session
#	
def selectMtpStorageId():

	mtpTcpCmdResult = mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_GetStorageIDs)
	mtpStorageIds = parseMptStorageIds(mtpTcpCmdResult.dataReceived)

	applog_d("All Storage IDs:")
	for i in xrange(0, len(mtpStorageIds.storageIdsList)):
		applog_d("  storageId[{:d}] = 0x{:08x}".format(i, mtpStorageIds.storageIdsList[i]))
		
	storageId = 0
	if mtpStorageIds.storageIdsList:	# if list is not empty (never should be)
		if g.args['slot'] == 'firstfound':
			# use first slot we find populated
			for i in xrange(0, len(mtpStorageIds.storageIdsList)):
				if (mtpStorageIds.storageIdsList[i] & MTP_STORAGEID_PresenceBit):
					storageId = mtpStorageIds.storageIdsList[i]
					break;
		else:
			if g.args['slot'] == 'first':
				storageId = mtpStorageIds.storageIdsList[0]
			elif g.args['slot'] == 'second':
				if len(mtpStorageIds.storageIdsList) >= 2: # if camera has at least two slots
					storageId = mtpStorageIds.storageIdsList[1]
				else:
					applog_e("Second card slot specified but camera only has one card slot!")
					sys.exit(ERRNO_NO_CARD_MEDIA_AVIALABLE)
	applog_d("  storageId to be used for this invocation: {:08x}".format(storageId))
	if (storageId & MTP_STORAGEID_PresenceBit) == 0:
		applog_e("No card present in specified slot or card is busy!")
		sys.exit(ERRNO_NO_CARD_MEDIA_AVIALABLE)
	g.storageId = storageId

	
#
# performs a MTP_OP_GetStorageInfo and saves the information into g.MtpStorageInfo
#
def getMtpStorageInfo():
	mtpTcpCmdResult = mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_GetStorageInfo, struct.pack('<I', g.storageId))
	g.MtpStorageInfo = parseMtpStorageInfo(mtpTcpCmdResult.dataReceived)
	applog_d(g.MtpStorageInfo)


#
# attempts deletion of a file, ignoring any errors
#
def deleteFileIgnoreErrors(filename):
	try:
		os.remove(filename)
	except:
		pass


#
# generates and saves a cache of all the MtpObjectInfo(s) we've retrieved this session.
# this is done to avoid having to re-retrieve these same MtpObjectInfo instances from
# the camera on subsequent sessions. we generate the cache by serializing the 
# MtpObjectInfo instances (and handle instances) via python's pickle's module. 
#		
MtpObjectInfoCacheTuple = namedtuple('MtpObjectInfoCacheTuple', 'mtpObjectInfoList objHandlesList timeSavedEpoch')
def saveMtpObjectInfoCacheToDisk():

	if g.args['mtpobjcache'] == 'disabled' or g.args['mtpobjcache'] == 'readonly':
		return None	
	
	mtpObjectInfoCacheFilename = g.cameraLocalMetadataPathAndRootName + "-objinfocache"

	#
	# build mtpObjectInfoList[] and objHandlesList[] from the mtpObject entries that were
	# inserted by buildMtpObjects(). I'm rebuilding the lists here rather than using the
	# locally-available lists in buildMtpObjects() because I wanted this routine to
	# be callable in the future outside of just buildMtpObjects()
	#
	mtpObjectInfoList = []
	objHandlesList = []
	countObjs = MtpObject.getCount()
	mtpObject = MtpObject.getOldest()
	for nObjInex in xrange(0, countObjs):
		mtpObjectInfoList.append(mtpObject.mtpObjectInfo)
		objHandlesList.append(mtpObject.mtpObjectHandle)
		mtpObject = mtpObject.getNewer()
		
	#
	# generate the named-tuple (structure) that we'll be serializing to disk. this tuple
	# contains the mtpObjectInfoList[] and objHandlesList[] lists generated above, plus
	# a timestamp that can be used to evaluate the age of the cache in future invocations
	#
	mtpObjectInfoCacheTuple = MtpObjectInfoCacheTuple(mtpObjectInfoList, objHandlesList, time.time())

	#
	# build a hash of the tuple, which will be saved in the serialization data with the tuple. this
	# hash will allow us to validate the integirty of the serialized data when we use load it
	# on subsequent invocations to use as a cache. this validation is to protect against:
	#
	# -> Corruption of the cache data if the user inadvertently modifies the file holding the data
	# -> Future changes to the content of the cache data (a version number would work but since we're already generating the hash....)
	# -> Future changes to the python pickle implementation or the algorithm we use
	#
	# when loadMtpObjectsInfoCache() load this serialization data he generates a hash of the loaded
	# data and compares it against the hash that was generated+saved here
	#
	mtpObjectInfoCacheAsPickleBytes = pickle.dumps(mtpObjectInfoCacheTuple)	# generate byte array of the tuple
	hashOfMtpObjectInfoCacheTuple = hashlib.sha512(mtpObjectInfoCacheAsPickleBytes).hexdigest()	# generate a SHA-512 hash digest, represented in hex ASCII

	#
	# write the serialization data. if any error occurs, either I/O error or pickling/code error,
	# we close the file and delete it, to prevent any partially-written cache data from lingering
	# on disk. any error is treated as benign since the cache is not essential to the operation
	# of the program - it's only a performance optimization
	#
	try:
		fMtpObjectCache = open(mtpObjectInfoCacheFilename, "wb")
		fMtpObjectCache.write(mtpObjectInfoCacheAsPickleBytes)			# write the tuple. note we're using the already-pickled data instead of calling dump(). this is for performance
		pickle.dump(hashOfMtpObjectInfoCacheTuple, fMtpObjectCache)		# write the SHA-512 hash digest
		fMtpObjectCache.close()
	except IOError as e:
		if fMtpObjectCache:
			fMtpObjectCache.close()				
		applog_e("I/O error writing obj hash to {:s}, cache will not be available next session: {:s}".format(mtpObjectInfoCacheFilename, str(e)))
		deleteFileIgnoreErrors(mtpObjectInfoCacheFilename)	# delete cache in case some (partial) data was written before exception
	except (ImportError, pickle.PickleError, ValueError):
		# ImportError if the serialized data refers to a module that doesn't exist (changed module names between versions)
		# PickleError if the decoding of the serialized data failed (corrupt data, modified format between versions, etc...
		# ValueError if importing from different pickle protoocl
		applog_d("Exception serializing obj cache:\n")
		applog_d(traceback.format_exc())	
		if fMtpObjectCache:
			fMtpObjectCache.close()				
		applog_e("Non-I/O error generating obj hash to {:s}, cache will not be saved.".format(mtpObjectInfoCacheFilename))
		deleteFileIgnoreErrors(mtpObjectInfoCacheFilename)	# delete cache in case some (partial) data was written before exception
				

#
# loads the MtpObjectInfo cache info that was saved to disk on a previous session by
# saveMtpObjectInfoCacheToDisk(). if the cache is loaded successfully and passes the
# hashed integrity check then a MtpObjectInfoCacheTuple is returned. note that 
# even if the cache is loaded successfully the caller must perform his own coherency
# check to make sure the cache contents are valid vs the objects on the camera. 
#
def loadMtpObjectInfoCacheFromDisk():

	if g.args['mtpobjcache'] == 'disabled':
		return None	

	mtpObjectInfoCacheFilename = g.cameraLocalMetadataPathAndRootName + "-objinfocache"
	
	#
	# read  the serialization data. if any error occurs, either I/O error or pickling/code error 
	# we close the file. we only delete the file if the hash is corrupt; that way the cache will
	# still be available on future invocations in case the I/O error we got here was transitory (even
	# though the file is about to get rewritten anyway once we fetch the objects from the camera and
	# later call saveMtpObjectInfoCacheToDisk). any error is treated as benign since the cache is not
	# essential to the operation of the program - it's only a performance optimization
	#	
	if os.path.exists(mtpObjectInfoCacheFilename):
		if g.args['mtpobjcache'] == 'writeonly':
			applog_v("Ignoring found MTP object cache file per user configuration")
			return None
		fMtpObjectCache = None # needed so that exception handlers can know whether the file was opened before the exception and thus needs closing
		try:
			fMtpObjectCache = open(mtpObjectInfoCacheFilename, "rb")
			mtpObjectInfoCacheTuple = pickle.load(fMtpObjectCache)
			hashOfMtpObjectInfoCacheTuple_Loaded = pickle.load(fMtpObjectCache)
			fMtpObjectCache.close()
			
			mtpObjectInfoCacheAsPickleBytes = pickle.dumps(mtpObjectInfoCacheTuple)
			hashOfMtpObjectInfoCacheTuple_Calculated = hashlib.sha512(mtpObjectInfoCacheAsPickleBytes).hexdigest()
		except IOError as e:
			if fMtpObjectCache:
				fMtpObjectCache.close()				
			applog_e("I/O error reading obj hash from {:s}: {:s}".format(mtpObjectInfoCacheFilename, str(e)))
			return None
		except (ImportError, pickle.PickleError, ValueError):
			# ImportError if the serialized data refers to a module that doesn't exist (changed module names between versions)
			# PickleError if the decoding of the serialized data failed (corrupt data, modified format between versions, etc...
					# ValueError if importing from different pickle protoocl
			applog_d("Exception deserializing obj cache:\n")
			applog_d(traceback.format_exc())	
			if fMtpObjectCache:
				fMtpObjectCache.close()				
			applog_e("Non-I/O error reading obj hash from {:s}. Cache will be discarded.".format(mtpObjectInfoCacheFilename))
			deleteFileIgnoreErrors(mtpObjectInfoCacheFilename) # delete the potentially corrupt cache
			return None

		#
		# cache was read successfully. verify its integrity
		#
		if hashOfMtpObjectInfoCacheTuple_Loaded != hashOfMtpObjectInfoCacheTuple_Calculated:			
			applog_e("Obj cache in {:s} is corrupt - will delete and ignore".format(mtpObjectInfoCacheFilename))
			fMtpObjectCache.close()
			deleteFileIgnoreErrors(mtpObjectInfoCacheFilename)	# delete the corrupt cache
			return None
			
		#
		# have valid cache
		#
		cacheAgeSeconds = time.time() - mtpObjectInfoCacheTuple.timeSavedEpoch
		
		# display cache info (verbose/debug)
		applog_v("MTP Object cache has {:d} objects, age is {:s}".\
			format(len(mtpObjectInfoCacheTuple.mtpObjectInfoList), str(datetime.timedelta(seconds=cacheAgeSeconds))))
		if isDebugLog():
			applog_d("MTP object cache entries [count={:d}]".format(len(mtpObjectInfoCacheTuple.mtpObjectInfoList)))
			for i in xrange(len(mtpObjectInfoCacheTuple.mtpObjectInfoList)):
				applog_d("Entry {:4d}, handle = 0x{:08x}: {:s}".format(i, mtpObjectInfoCacheTuple.objHandlesList[i], mtpObjectInfoCacheTuple.mtpObjectInfoList[i]))
				
		#
		# ignore (discard) cache if its older than the max configured age
		#
		if g.args['mtpobjcache_maxagemins'] != 0 and cacheAgeSeconds/60 >= g.args['mtpobjcache_maxagemins']:
			applog_v("Discarding MTP object cache due to age (max age is {:s})".format(str(datetime.timedelta(minutes=g.args['mtpobjcache_maxagemins']))))
			return None
			
		return mtpObjectInfoCacheTuple
			
	else:
		return None


#
# Loads the MPT object info cache from the previous session (if available) and validates
# the cache's coherency. The coherency must be checked because MTP object handles
# aren't guaranteed to be persistent across camera power cycles (per the MTP spec), which
# means an obj handle may refer to a different file on the camera than what we have
# cached from the previous airnef session. This makes the entire proposition of caching
# these objs a bit risky, but the performance beneifts are too great to ignore because
# MTP_OP_GetObjectInfo can operate very slowly on some Nikon bodies. Based on my
# experimentation both Nikon and Canon encode object handles based on the filename
# and/or directory, the slot the media card is in, etc... This of course means that
# object handles can be reused and become stale relative to our cache, such as when
# users reformat cards and the same directory and filenames get reused to new images.
# What's needed is a way to detect when the camera might have reused an object handle
# in this fashion, short of performing MTP_OP_GetObjectInfo for all handles and defeating
# the purporse of the cache in the first place. The solution I came up with is to perform
# a spot check of just the directory objects, ie we perform MTP_OP_GetObjectInfo's for
# the directories we have in our cache, and compare the downloaded copies to our cache.
# If any directory object mismatches, specifically the timestamps, this means it's
# nearly certain that we have a a stale object cache and need to discard it.
#
# The directory timestamps will mismatch for any number of reasons, some of which
# are listed below. All signify a stale cache except for #3, which we'll still
# invalidate for since it doesn't make sense to get tricky for such an uncommon usage case.
#
#   1) There's a different media card in the camera
#   2) The user formatted the same media card
#   3) The user moved the media card to a different slot (on Nikon this flips a bit in the handles)
#   3) The user modified one or more files with the card inserted in an SD reader (unlikely)
#
# It's important to note some observations about how Nikon and Camera maintain timestamps on
# folders. On Nikon, the base DCIM directory uses a fixed timestamp of "19800000T000000" and
# the timestamp is never updated. This would be bad since we're relying on the timestamps for
# this algorithm; luckily this behavior is limited to the base DCIM directory. For all
# subdirectories under DCIM (that actually hold images), Nikon sets the timestamp of the folder
# at the time the folder is created, either after a card format or when a new folder is created
# when the image count in a folder exceeds 999 or 9999. Luckily nether Canon or Nikon keep
# the timestamps of these subfolders updated thereafter - they always keep the same timestamp
# even when images are being added to them (technically a filesystem's folder timestamp should
# update when any file within it is updated - they're probably avoiding doing so for performance
# reasons) - this is lucky for us because if they were to update the timestampsthen our algorithm
# would always find mismatching folder timestamps whenever there are new images in the folder.
# Note that any new directories on the camera (not in our cache) don't influence the algorithm
# since their existence doesn't affect the coherency of the directories we do have cached. 
#
# When a cache has been successfully loaded and validated this function returns a dictionary
# where the key is the object handle and the value is the cached MtpObjectInfo - the caller
# can then use the dictionary to perform a O(1) lookup against the object handle list
# obtained from the camera to know which objects it has available in the cache and thus
# can avoid a time-consuming MTP_OP_GetObjectInfo oeration. If the cache could not be loaded
# or is corrupt or the user has the cache disabled via a command-line arg or if coherency
# check performed by this function determines the cache is stale then None is returned.
#
# FYI, here's some analysis of how Nikon encodes obj handles (from the D7200):
#
# 0x0a19018e for DCIM\100D7200\DSC_0398.NEF (slot 2)
#        ^^^ ----> the 0x18e is the filename number (398 in hex)
#       ^ -------> the 0 is the directory number, encoded in some form
#    ^ ----------> the A means slot 2
#
# 0x0a19418e for DCIM\101D7200\DSC_0398.NEF (slot 2)
#        ^^^ ----> the 0x18e is the filename number (398 in hex)
#       ^ -------> the 4 is the directory number, encoded in some form
#    ^ ----------> the A means slot 2
#
# 0x0919418e for DCIM\101D7200\DSC_0398.NEF (slot 1)
#        ^^^ ----> the 0x18e is the filename number (398 in hex)
#       ^ -------> the 4 is the directory number, encoded in some form
#    ^ ----------> the 9 means slot 1
#
def loadAndValidateMtpObjectInfoCacheFromDisk(objHandlesFromCameraList):
	mtpObjectInfoCacheTuple = loadMtpObjectInfoCacheFromDisk()
	if not mtpObjectInfoCacheTuple:
		# no cache found or it failed its integrity test or usage was disabled by user configuration, etc...
		return None
	
	#
	# build a set of the camera's current object handles so that we can quickly do memebership
	# tests of our cached object handles for the directory entries we're checking. any miss
	# means that the cached directory handle we have is no longer present on the camera (or
	# less likely, the same card was moved to a different slot so that the encoded slot 
	# number in Nikon's object handle will now be different). this doesn't absolutely mean that
	# our other (file) objects are invalid but it probably does, and either way to be safe
	# we'll discard the cache in this case
	#
	objHandlesFromCameraSet = set(objHandlesFromCameraList) 
		
	#
	# the following loop scans through all the cached objects to perform two tasks:
	#
	# 1) Validate all objects that are directory entries by downloading the objects at those handles and verifying
	#    the directories are identical in name, date, etc.. If there is a mismatch then that means the cached object
	#    info we have is stale and the cache needs to be discaded
	#
	# 2) Builds dictionary that hashes the cached object handles to cached cached MtpObjectInfo objects - we'll use this
	#    to match up the object handles in the MTP_OP_GetObjectInfo loop to know which objects we have cached and thus
	#    don't have to fetch from the camera
	#
	# The tasks are somewhat unrelated but I'm performing them in the same loop as an optimziation.
	#
	bInvalidateCache = False
	cachedMtpObjectInfoListDict = {}
	for nObjIndex in xrange(0, len(mtpObjectInfoCacheTuple.mtpObjectInfoList)):
	
		objHandle = mtpObjectInfoCacheTuple.objHandlesList[nObjIndex]
		cachedMtpObjectInfo = mtpObjectInfoCacheTuple.mtpObjectInfoList[nObjIndex]

		# put cached object in cache dictionary we're building
		cachedMtpObjectInfoListDict[objHandle] = cachedMtpObjectInfo
					
		if mtpObjectInfoCacheTuple.mtpObjectInfoList[nObjIndex].associationType != MTP_OBJASSOC_GenericFolder:
			# this object is not a directory - nothing more to do with it
			continue
			
		#
		# this is a directory object. first make sure that this object handle 
		# still exists on the camera by checking it against the object handle
		# list obtained from the camera. if the handle doesn't even exist then
		# we know the directory is gone and we can immediately establish the 
		# cache is stale
		#
		if objHandle not in objHandlesFromCameraSet:
			applog_d("MTP obj handle 0x{:08x} for cache directory object \"{:s}\" does not exist".format(objHandle, cachedMtpObjectInfo.filename))
			bInvalidateCache = True
			break

		#
		# the directory object handle still exists on the camera. now we need
		# to perform a MTP_OP_GetObjectInfo of the handle and compare it against
		# our cached copy to confirm its the same directory/timestamp
		#		
		try:
			applog_d("Validating MTP obj cache directory object \"{:s}\" on handle 0x{:08x}".format(cachedMtpObjectInfo.filename, objHandle))
			mtpTcpCmdResult = mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_GetObjectInfo, struct.pack('<I', objHandle))
		except mtpwifi.MtpOpExecFailureException as e:
			if e.mtpRespCode == MTP_RESP_COMMUNICATION_ERROR:
				# request failed for reasons other than camera reporting an MPT error on the
				# cmd itself (ie, delivery of command failed) propagate exception and leave
				raise
			#
			# request failed, which really shouldn't happen because we already know the
			# object handle should be valid, even if the object data associated with it
			# might be stale. since we can't determine whether its stale without
			# successfully completing a MTP_OP_GetObjectInfo we'll just invalidate
			#
			applog_d("MTP object cache validation of \"{:s}\" resulted in {:s}".format(cachedMtpObjectInfo.filename, str(e)))
			bInvalidateCache = True
			break
			
		#
		# obtained the object data from the camera. now compare against our cached copy
		#
		mtpObjectInfo = parseMtpObjectInfo(mtpTcpCmdResult.dataReceived)
		if mtpObjectInfo != cachedMtpObjectInfo:
			# mismatches - the most likely cause is the timestamp
			applog_v("Found mismatch in MTP object cached directory \"{:s}\"".format(cachedMtpObjectInfo.filename))
			applog_d("    Cached copy: {:s}".format(cachedMtpObjectInfo))
			applog_d("Downloaded copy: {:s}".format(mtpObjectInfo))
			bInvalidateCache = True
			break;
								
	if bInvalidateCache:
		# generate a message if the cache was invalidated for any reason
		applog_v("The MTP object cache was detected as stale and will be discarded")
		return None
		
	#
	# cached passed all the coherency checks. it's good! hopefully :)
	#
	return cachedMtpObjectInfoListDict


#
# Enumerates all MTP objects on the camera, creating instances of our MtpObject()
# class for each object found.
#
# Some Background: In MTP, every file and folder on the camera is represented by
# an MTP object, which contains information such as the file's type, name,
# size, image dimensions, timestamps, etc.. Rather than passing full objects
# around for each MTP command, every object is represented by a unique MTP
# object handle, which is an opaque (to us anyway) 32-bit handle.
#
# The full list of all object handles for a given media card can be quickly
# obtained via the MTP_OP_GetObjectHandles. Then the slow part comes - we have
# to perform a MTP_OP_GetObjectInfo against each of those handles to get
# the actual MTP object info (ie, filename, size, type, etc...). The process
# enumerating through all the handles via MTP_OP_GetObjectInfo was found to
# be intermittently very slow on Nikon cameras, esp when performed for the first
# time after the camera has been powered on or if the media card was swapped out
# while the camera was on. To help ameliorate this we cache the MTP objects
# across arnef sessions on a per camera and S/N basis, so that we can at least
# avoid having to download the same objects on subsequent sessions, assuming
# they still exist in the camera on those subsequent sessions. Caching has its
# risks because MTP states that the object handles aren't persistent across
# camera sessions - see the comments in loadAndValidateMtpObjectInfoCacheFromDisk()
# for details on how we maintain coherency of the cache.
# 
def buildMtpObjects():

	# check if camera has a transfer list (user-selected images on camera). if so, download it
	g.bReceivedTransferListFromCamera = False
	if g.args['cameratransferlist'] != 'ignore':
		try:
			mtpTcpCmdResult = mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_GetTransferList)
			(objHandlesList, bytesConsumed) = parseMtpCountedWordList(mtpTcpCmdResult.dataReceived)
			numObjectHandles = len(objHandlesList)
			g.bReceivedTransferListFromCamera = True
			applog_i("Transfer list detected in camera - {:d} images/file(s) will be downloaded".format(numObjectHandles))
		except mtpwifi.MtpOpExecFailureException as e:
			#
			# we ignore non-MTP_RESP_COMMUNICATION_ERROR errors, since it's normal for this
			# command to fail when the camera doesn't have a transfer list. Most bodies
			# return MTP_RESP_NoTransferList. The WU-1a returns 0xa081.
			#
			if (e.mtpRespCode == MTP_RESP_COMMUNICATION_ERROR):
				raise
			# else the error is normal and means the user didn't selected any images for upload in the camera
		
	if not g.bReceivedTransferListFromCamera:
	
		if g.args['cameratransferlist'] == 'exitifnotavail':
			applog_e("Camera reports no user-selected images/movies to transfer/or not-supported")
			sys.exit(ERRNO_NO_CAMERA_TRANSFER_LIST)

		#
		# not using a user-selected transfer list. get the full MTP object list from the camera. we
		# first perform a MTP_OP_GetNumObjects, which really isn't necessary since we get the same
		# information from MTP_OP_GetObjectHandles. i'm keeping it here in case we ever want to
		# use it for extra validation
		#
		mtpTcpCmdResult = mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_GetNumObjects, struct.pack('<I', g.storageId))
		numObjectsForStorageId = mtpTcpCmdResult.mtpResponseParameter
		applog_d("numObjectsForStorageId = {:d}".format(numObjectsForStorageId))
	
		mtpTcpCmdResult = mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_GetObjectHandles, struct.pack('<I', g.storageId))
		(objHandlesList, bytesConsumed) = parseMtpCountedWordList(mtpTcpCmdResult.dataReceived)
		numObjectHandles = len(objHandlesList)
	
	if isDebugLog():
		applog_d("MTP object handles (count={:d}):".format(numObjectHandles))
		applog_d(strutil.hexdump(mtpTcpCmdResult.dataReceived[4:], bytesPerField=4, includeASCII=False))

	#
	# load MtpObjectInfo cache from previous session. if the cache was not available or
	# was found to be stale then cachedMtpObjectInfoListDict will be None
	#
	cachedMtpObjectInfoListDict = loadAndValidateMtpObjectInfoCacheFromDisk(objHandlesList)

	#
	# process all the object handles
	# 
	countMtpObjectInfoCacheHits = 0
	for nObjIndex in xrange(0, numObjectHandles):
		
		consoleWriteLine("\rRetrieving list of images/files from camera: {:d}/{:d}     ".format(nObjIndex, numObjectHandles))
		objHandle = objHandlesList[nObjIndex]
		
		#
		# check if we've already created an MtpObject for this handle. this is possible if 
		# a previous invocation of this method was interrupted due to an error and this
		# invocation is a retry
		#
		if MtpObject.getByMtpObjectHandle(objHandle):
			applog_d("MtpObject for handle 0x{:08x} already exists, skipping".format(objHandle))
			continue

		#
		# used for debugging only, we support an option for verification of the full object
		# cache, vs just the directory-based coherency algorithm in loadAndValidateMtpObjectInfoCacheFromDisk()
		# when enabled we always perform a MTP_OP_GetObjectInfo and do a comparison against
		# the object we have in cache (if we have it in cache)
		#
		bIsInCache = cachedMtpObjectInfoListDict and (objHandle in cachedMtpObjectInfoListDict)
		if bIsInCache:
			countMtpObjectInfoCacheHits += 1
		if (bIsInCache and g.args['mtpobjcache'] != 'verify'):
			# found mtpObjectInfo for this handle in the cache - use cached copy
			applog_d("Found objHandle 0x{:08x} in cache".format(objHandle))
			mtpObjectInfo = cachedMtpObjectInfoListDict[objHandle]
		else:
			# didn't find mtpObjectInfo for this handle in the cache or we're validating cache - get the mtpObjectInfo from the camera
			mtpTcpCmdResult = mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_GetObjectInfo, struct.pack('<I', objHandle))
			mtpObjectInfo = parseMtpObjectInfo(mtpTcpCmdResult.dataReceived)
			if bIsInCache:
				# we're validating cache
				if mtpObjectInfo != cachedMtpObjectInfoListDict[objHandle]:
					applog_e("Found MTP object cache mismatch for \"{:s}\" vs  \"{:s}\"".format(mtpObjectInfo.filename, cachedMtpObjectInfoListDict[objHandle].filename))
					applog_e("    Cached copy: {:s}".format(str(cachedMtpObjectInfoListDict[objHandle])))
					applog_e("Downloaded copy: {:s}".format(str(mtpObjectInfo)))
					sys.exit(ERRNO_MTP_OBJ_CACHE_VALIDATE_FAILED)

		#
		# create and add instance of MtpObject for this MtpObjectInfo
		#
		mtpObj = MtpObject(objHandle, mtpObjectInfo)
		
		# if we received a transfer list from the camera, mark this object as being in the transfer list 
		if g.bReceivedTransferListFromCamera:
			mtpObj.setInCameraTransferList()
		
	consoleClearLine()
	applog_i("Retrieved info for {:d} images/files/dirs [{:d} from object cache]".format(numObjectHandles, countMtpObjectInfoCacheHits))
	
	if not g.bReceivedTransferListFromCamera:	
		g.bDownloadedPartialMtpObjList = False
	else:
		g.bDownloadedPartialMtpObjList = True

	#
	# serialized object list to file to cache it for future sessions. note that if we're
	# processing a transfer list this session then the object list we're serializing to cache
	# will be limited to only the transfer list objects, potentially discarding a full cache
	# from a previous, non-transfer list session. I considered adding logic to merge the
	# transfer list objects into the existing cache but decided against it for now
	#
	saveMtpObjectInfoCacheToDisk()


#
# returns the file extension of an MTP-obtained filename
#
def extractMtpFileExtension(fileNameStr):
	fileExtensionPos = fileNameStr.rfind(".", 0)
	if fileExtensionPos == -1:
		return ""
	extensionStr = fileNameStr[fileExtensionPos+1:]
	return extensionStr	# may be empty string if there were no characters after final "." in filename	


#
# generates a unique filename based on an original name by
# adding a -new-%d suffix, repeating until it finds a suffix
# number that's unique for the directory the file is in
#
def generateUniqueFilename(origFilenameWithPath):
	newSuffixCounter = 1
	while True:
		rootfilename = os.path.splitext(origFilenameWithPath)
		newFilename = "{:s}-new-{:d}{:s}".format(rootfilename[0], newSuffixCounter, rootfilename[1])
		if not os.path.exists(newFilename):
			return newFilename
		newSuffixCounter += 1
		

#
# prompts the user for a single-character selection (+enter),
# only allowing characters specfied in validKeyList. check
# is case-insensitive.
# 		
def promptWithSingleKeyResponse(promptStr, validKeyListStr):
	while True:
		key = raw_input(promptStr).upper()
		if key and validKeyListStr.upper().find(key.upper()) != -1:
			return key			

	
#
# Open/create download history file for this camera. We use this file to track
# which images we've alread downloaded in previous invocations, allowing the
# user to optionally skip these files for this or future invocations. 
#
# The history file contains one line of text for every file downloaded. The text
# is separated into two areas - a 'key area' and an 'additional info' area. The key
# area doubles as a unique identifier for a particular file along with holding
# information about the file. The 'addtional info' area has extra info about the
# download of the file, including a time stamp of when it was download and the path
# it was downloaded to.
#
# Here's the format of the history line for a file:
#
# 	localFilenameWithoutPath::MTP capture data str::Size in human-readable comma form::::download date/time string::outputDirPathAbsolute
#
# Examples:
#	DSC_0094.NEF::20150804T120900::22,719,774:::05/05/15 13:44::c:\pics
#	DSC_2570.JPG.sthumb.jpg::20150828T112418::3,419,512::::09/02/15 22:22:43::c:\pics\vacation
#
# The 'key area' and 'additional info area' are demarcated by four consecutive colons.
# Each field within those areas are separated by two consecutive colons. The 'key area'
# has enough information to uniquely identify a file and protect against false history
# positives/negatives, since it's the combination of the (camera-generated) filename,
# capture date+time, and file size. The likelihood that the camera's reuse of the filename will 
# have the same capture date+time and size should be nearly impossible.
#
# Generation of the history text to store in the history file is simple. Loading and using that
# history for the skip-alreayd-downloaded feature (on subsequent sessions) requires a little more
# work. To accomplish this we load and parse the file into a Python dictionary, with the 'key area'
# serving as the dictionary key and the 'addtional info area' serving as the value. Before downloading
# a file we build the history key and additional area strings for this session and then do a membership
# test of the key string against the dictionary we built from the history; if the keys match and
# we've been instructed to skip matches for this session then we wont download the file. If those
# conditions aren't met then we do download the file and then use the built key/additional area strings
# to generate the history event in the file.
#
# Some additional notes:
#
# I use 'localFilenameWithoutPath' insead of 'mtpObject.mtpObjectInfo.filename' so that we can
# track separate history for different types of downloads of the same file (full-sized, small thumbnail,
# and large thumbnail). 
#
# Even if we've been instructed to ignore the history this session (ie, to download files even if
# they're in the history), we still store entries for files we download this session, to support
# the ability of future sessions to skip these files if the user desires.
#	
def loadDownloadHistory():
	downloadHistoryDict = None
	downloadHistoryFilename = g.cameraLocalMetadataPathAndRootName + "-downloadhist";
	if (os.path.exists(downloadHistoryFilename)):
		if g.args['downloadhistory'] == 'clear':
			#
			# user instructed clearing the history file. we'll delete the file but then recreate it to allow
			# history to be generated for the files we download this session. since we're deleting the history
			# file there wont be any history to use for this session, thus no files will be skipped this session
			#
			applog_v("Deleting download history file \"{:s}\" per user configuration".format(downloadHistoryFilename))
			os.remove(downloadHistoryFilename)
		else:
			#
			# load download history into a dictionary. the 'downloadHistoryDict =' composite below separates the
			# 'key area' and 'additional info area' so that a dictionary entry is created for each line in the file.
			# here is a break-down of that line to make it easier to understand:
			#
			#   downloadHistoryDict = { for line in f } - the entire block is in curly braces, indicating a dictionary is
			#	being built. The expression starts by reading a line from the file into variable 'line'
			#
			# 	The left side of the expression then builds the key from the string loaded into 'line':
			#
			#		"{:s}".format(line[0:line.index("::::")])
			#		The 0: specifies the string starts at character 0. The end of the string is determined by
			#		line.index(":::"), which does a forward pattern match looking for the ":::" separator between the
			#		'key area' and 'additional info' area. index() returns the starting character position of the ":::",
			#		which serves as our ending subscript for the string of the 'key area'. The "{:s}" isn't really
			#		necessary but makes clear that the expression results in a string.
			#
			#	The right side of the expression then builds the 'additonal info area' from the string loaded into 'line':
			#
			#		"{:s}".format(line[line.index("::::", 0)+4: line.rindex("\n")])
			#		The line.index(":::", 0)+4 does the same pattern match performed on the key to find the same separator,
			#		but this time adds 4 to the result to get the starting charactor position of the substring we're extracting.
			#		The ending character position of the substring is determined via line.rindex("\n"), which finds the newline
			#
			#	Note that both index() and rindex() throw an exception if their substring searches fail - we catch this
			#	exception and report the history file as corrupt when we do. We then ignore its contents and delete the file,
			#	allowing a fresh file to be created when we reopen it for writing at the end of the routine
			#
			try:
				with open(downloadHistoryFilename) as f:
					downloadHistoryDict = { "{:s}".format(line[0:line.index("::::")])  :  "{:s}".format(line[line.index("::::", 0)+4: line.rindex("\n")]) for line in f }
				applog_v("Download history file \"{:s}\" loaded - {:d} entries".format(downloadHistoryFilename, len(downloadHistoryDict)))
			except ValueError:
				applog_e("Download history file \"{:s}\" appears corrupt and will be ignored and deleted".format(downloadHistoryFilename))
				os.remove(downloadHistoryFilename)
			except IOError as e:
				applog_e("Error openg/reading download history file \"{:s}\". No history will be available this session.".format(downloadHistoryFilename))
	else:
		applog_v("Download history file \"{:s}\" not found - will create".format(downloadHistoryFilename))
		
	#
	# re(open) the download history file for appending to support new history entries generated
	# this session. return both the download history dictionary and the reopened history file
	#
	fileDownloadHistory = open(downloadHistoryFilename, "a")
	return (downloadHistoryDict, fileDownloadHistory)
	
	
#
# download progress callback for MTP get requests issued by processMtpObjects().
# displays the progress to console as a percentage of completion.
#			
def processMtpObjects_DownloadProgressCallback(bytesReceivedAllCurrentPayloads, totalBytesExpectedAllCurrentPayloads, bytesReceivedPriorPayloads, totalFileSizeIfKnown):
	if not hasattr(processMtpObjects_DownloadProgressCallback, "lastPctPrinted"):
		processMtpObjects_DownloadProgressCallback.lastPctPrinted = -1 # static var to track last percentage printed, to avoid unnecessary updates

	bytesReceived = bytesReceivedAllCurrentPayloads + bytesReceivedPriorPayloads
	if totalFileSizeIfKnown:
		totalObjSizeBytes = totalFileSizeIfKnown
	else:
		totalObjSizeBytes = totalBytesExpectedAllCurrentPayloads		
	pctDone = float(bytesReceived) / totalObjSizeBytes * 100
	if int(pctDone) != int(processMtpObjects_DownloadProgressCallback.lastPctPrinted):
		# only update if it's changed. it's ok if we miss a single % update when switching files
		processMtpObjects_DownloadProgressCallback.lastPctPrinted = pctDone
		if pctDone == 100:
			consoleWriteLine("\b\b\b100%")
		else:
			pctDone = min(pctDone, 99) # don't let format() below round up to 100% - it'll screw up the print
			consoleWriteLine("\b\b\b{:2.0f}%".format(pctDone))

#
# writes data to a file being downloaded from the camera. 
#			
def writeDataToDownloadedFile(fileHandleIfAlreadyOpen, filenameWithPath, data, bCloseAfterWriting, bIsAppending):
	applog_d("{:s} writing 0x{:x} bytes, closeAfterWriting={:d}".format(filenameWithPath, len(data), bCloseAfterWriting))
	#
	# during a download we use a .part name in case we exit abnormally without being able to
	# clean up (delete) the file - that way the user doesn't think he has a valid image/movie file
	# for incomplete downloads
	#
	fileNameTemp = filenameWithPath + ".part"
	fo = fileHandleIfAlreadyOpen
	try:
		if fo == None:
			if fileNameTemp not in g.filesToDeleteOnAppExit:
				#
				# add the file to the delete list in case either the write we're
				# about to perform fails or if the (potentially) ongoing download
				# fails. we do this because we don't want to leave a file around
				# which has only partailly downloaded data. it's up to the
				# caller to remove the file from the delete list when he deems
				# it safe - we can't do it here after writing in case we're only
				# writing one piece and the caller still wants to close the file,
				# such as after receiving a partial piece during an MTP error
				#
				g.filesToDeleteOnAppExit.append(fileNameTemp)
			if not bIsAppending:
				fo = open(fileNameTemp, "wb") # create/truncate and open for binary writing
			else:
				fo = open(fileNameTemp, "ab") # open for binary appending
		fo.write(data)
		if bCloseAfterWriting:
			fo.close()
			return None
		return fo		
	except IOError as e:
		if fo:
			fo.close()
		applog_e("\nError creating or writing to \"{:s}\". {:s}".format(filenameWithPath, str(e)))
		sys.exit(ERRNO_DOWNLOAD_FILE_OP_FAILED)

#
# if the user has specified to include the camera folder in the local output path, this routine
# will add the immediate camera folder to path, creating the local subdirectory if necessary
#		
def addCameraFolderToPath_CreateDirIfNecessary(baseAbsoluteOutputPath, mtpObject):
	if g.args['camerafolderinoutputdir'] == 'yes':
		cameraFolder = mtpObject.getImmediateDirectory()
		if cameraFolder:
			pathWithCameraFolder = os.path.join(baseAbsoluteOutputPath, cameraFolder)
			if not os.path.exists(pathWithCameraFolder):
				applog_v("Creating directory \"{:s}\"".format(pathWithCameraFolder))
				os.mkdir(pathWithCameraFolder)
			return pathWithCameraFolder
	return baseAbsoluteOutputPath
			
#
# Performs the user-specified action for application, which typically is to download
# images/movies from the camera bassed on criteria set via various command line options.
#
# When I first wrote this routine I was experiencing very flaky wireless behavior from
# all Nikon bodies I tested it with (D7200, J4, D750, WU-1a). About halfway through a
# NEF  download via MTP_OP_GetObject the transfer rate would become erratic and sometimes
# the camera would completely stop transferring and then eventually time out on a socket
# receive. It wouldn't do this on every file but about once every few files. To handle
# this behavior I added significant amounts of recovery logic, both in the low-levels
# of mtpwifi.py and the upper levels of this module (appMain), both of which were designed
# to retain any partially transferred data and allow the retry of downloads. Luckily when
# a Nikon body hits this condition it could  be revived by dropping the TCP/IP connection
# and restarting everything over again, from the opening of the TCP/IP socket through the
# MTP start session and back to this routine to retrieve the portion of the file we have
# left to download via MTP_OP_GetPartialObject.
#
# It later occured to me that the issue might be specific to Nikon's implementation of 
# MTP_OP_GetObject, as it appeared the camera's erratic behavior was related to how large
# the object was - JPEGs were fine but larger NEFs should issues and very large MOV
# files were the worst. It seemed the camera has some type of memory leak associated with
# the command, perhaps committing internal resources to the entire file rather than to each
# payload piece. So I experimented with transfers that relied solely MTP_OP_GetPartialObject,
# using varoius tranfers sizes, and confirmed my suspicion - there's a bug in Nikon's firmware
# related to large transfers, both from the atomic MTP_OP_GetObject request and also 
# large MTP_OP_GetPartialObject requests. Based on these results I rewrote this method
# to use only MTP_OP_GetPartialObject and with smaller transfer sizes and all the erratic
# Nikon behavior disappeared. Fortunately performance did not suffer - I found that using
# a transfer size of 1MB (vs the full object size in the orig implementation) yielded the
# same performance as the latter, and actually much better when you consider that we didn't
# have to go through time-consuming connection tear-downs and re-establishment cycles. On
# both my D7200 and J4 I see approx 2.3 MB/s of sustained xfer performance on the adhoc wifi
# conneciton when the camera is next to the computer.
#
# Resolving the transfer issue meant that all the retry logic I originally put in was now
# unnecessary. Rather than take it out I decided it best to leave it in place, to support
# any scenarios where the wifi connection can be marginal, such as when the camera is further
# away from the computer. I left the max-transfer size configurable, to allow for future
# tweaking/experimentation of different camera models, in g.maxGetObjTransferSize
#
def processMtpObjects():

	ActionToMtpOpDict = {								\
		'getfiles' 			: MTP_OP_GetObject,			\
		'getsmallthumbs' 	: MTP_OP_GetThumb,			\
		'getlargethumbs'	: MTP_OP_GetLargeThumb		\
	}
	
	applog_i("") # newline separator for logging

	bActionIsDownload = (g.args['action'] == 'getfiles' or g.args['action'] == 'getsmallthumbs' or g.args['action'] =='getlargethumbs')
	
	if '<ALL>' in g.args['extlist']:
		allFileExtensionsIncluded = True
		userSpecifiedExtensionsSet = ""
	else:
		allFileExtensionsIncluded = False
		userSpecifiedExtensionsSet = set([ x.upper() for x in g.args['extlist'] ]) # convert extensions to uppercase and also a set

	applog_d("File extensions included: " + str(userSpecifiedExtensionsSet))
	
	bScanningNewestFirst = g.args['transferorder'] == 'newestfirst'
	
	if bActionIsDownload:
	
		#
		# load download history and open history file for writing for new history to be generated this session
		#
		(downloadHistoryDict, fileDownloadHistory) = loadDownloadHistory()
		bSkipDownloadedFiles = (g.args['downloadhistory'] != 'ignore') and downloadHistoryDict # skip files if instructed to do so and download history was successfully loaded
		
		outputDirPathAbsolute = os.path.abspath(g.args['outputdir'])
		
	totalBytesOfImagesInObjectsListed = 0
	countFilesListed = 0
	countDirectories = 0
	countObjectsScannedThatAreLikelyFiles = 0
	
	for nObjIndex in xrange(0, MtpObject.getCount()):
	
		# select first/next object to work on
		if bScanningNewestFirst:
			if nObjIndex == 0:
				mtpObject = MtpObject.getNewest()
			else:
				mtpObject = mtpObject.getOlder()
		else:
			if nObjIndex == 0:
				mtpObject = MtpObject.getOldest()
			else:
				mtpObject = mtpObject.getNewer()

		if isDebugLog():
			applog_d("Processing handle 0x{:08x}: {:s}".format(mtpObject.mtpObjectHandle, str(mtpObject.mtpObjectInfo))) # dump MTP object info to debug log

		# count number of directories and likely file objects
		if mtpObject.mtpObjectInfo.objectFormat == MTP_OBJFORMAT_Assocation:
			countDirectories += 1
		elif mtpObject.mtpObjectInfo.objectFormat != MTP_OBJFORMAT_NONE:
			countObjectsScannedThatAreLikelyFiles += 1
			
		if g.bReceivedTransferListFromCamera == True:
			# user selected files in the camera - that becomes our exclusive criteria
			if not mtpObject.isInCameraTransferList():
				applog_v("Skipping {:s} - not in camera's transfer list".format(mtpObject.mtpObjectInfo.filename))
				continue

		else:
		
			if mtpObject.wasDownloadedThisSession():
				# file was already downloaded on a previous invocation of processMtpObjects()
				applog_d("Skipping {:s} - already downloaded this session".format(mtpObject.mtpObjectInfo.filename))
				continue
				
			#
			# skip objects that don't match user's criteria
			#		
					
			# first filter out objects that don't correspond to files
			if mtpObject.mtpObjectInfo.objectFormat == MTP_OBJFORMAT_Assocation or mtpObject.mtpObjectInfo.objectFormat == MTP_OBJFORMAT_NONE:
				applog_d("Skipping {:s} - object is not file - {:s}".format(mtpObject.mtpObjectInfo.filename, getMtpObjFormatDesc(mtpObject.mtpObjectInfo.objectFormat)))
				continue
			# filter against user-specified extensions
			extension = extractMtpFileExtension(mtpObject.mtpObjectInfo.filename)
			if extension: # if filename has an extension
				if (not allFileExtensionsIncluded) and (extension not in userSpecifiedExtensionsSet):
					applog_v("Skipping {:s} - filename extension not in user-specified list".format(mtpObject.mtpObjectInfo.filename))
					continue
			else: # file has no extension
				if (not allFileExtensionsIncluded) and ("<NOEXT>" not in userSpecifiedExtensionsSet):
					applog_v("Skipping {:s} - no file extension and \"<NOEXT>\" not included in extension list".format(mtpObject.mtpObjectInfo.filename))
					continue
				#
				# else: not certain how best to handle the case of files without extensions. presumably these are files
				# that the user wont be interested in but there may be cases where he is, so for now we'll allow these
				# files to pass the filter and be downloaded. may need to reevaluate this in the future
				#
			# filter against capture date range
			if g.objfilter_dateStartEpoch != None and mtpObject.captureDateEpoch < g.objfilter_dateStartEpoch:
				# user specified starting date filter and this object has a capture date earlier than specified filter
				applog_v("Skipping {:s} - has capture date earlier than user-specified start date filter".format(mtpObject.mtpObjectInfo.filename))
				continue
			if g.objfilter_dateEndEpoch != None and mtpObject.captureDateEpoch > g.objfilter_dateEndEpoch:
				# user specified ending date filter and this object has a capture date later than specified filter
				applog_v("Skipping {:s} - has capture date later than user-specified end date filter".format(mtpObject.mtpObjectInfo.filename))
				continue
				
			# filter against folders
			if g.args['onlyfolders']:
				cameraFolder = mtpObject.getImmediateDirectory()
				if (cameraFolder=="" and ("<root>" not in g.args['onlyfolders'])) or cameraFolder not in g.args['onlyfolders']:
					# image is in root directory of camera and "<root>" not in list, or image is in directory not in list
					applog_v("Skipping {:s}\\{:s} - folder not in --onlyfolders".format(cameraFolder, mtpObject.mtpObjectInfo.filename))
					continue
			if g.args['excludefolders']:
				cameraFolder = mtpObject.getImmediateDirectory()
				if (cameraFolder=="" and "<root>" in g.args['excludefolders']) or cameraFolder in g.args['excludefolders']:
					# image is in root directory of camera and "<root>" is in list, or image is in directory in list
					applog_v("Skipping {:s}\\{:s} - folder in --excludefolders".format(cameraFolder, mtpObject.mtpObjectInfo.filename))
					continue
					
			
									
		if g.args['action'] == 'listfiles':
			# format of listing is <date> <size in bytes> <full path>
			timeStr = time.strftime("%m/%d/%y %I:%M:%S %p", time.localtime(mtpObject.captureDateEpoch))
			sizeStr = "{:13,}".format(mtpObject.mtpObjectInfo.objectCompressedSize)
			fullPathStr = mtpObject.genFullPathStr()
			applog_i("{:s}  {:s} {:s}".format(timeStr, sizeStr, fullPathStr))
			totalBytesOfImagesInObjectsListed += mtpObject.mtpObjectInfo.objectCompressedSize
			countFilesListed += 1
	
		elif bActionIsDownload:

			mtpOpGet = ActionToMtpOpDict[g.args['action']]
			
			# build local filename that will hold image
			filenameWithObjTypeSuffix = mtpObject.mtpObjectInfo.filename
			if mtpOpGet == MTP_OP_GetThumb:
				filenameWithObjTypeSuffix += ".sthumb.jpg"
			elif mtpOpGet == MTP_OP_GetLargeThumb:
				filenameWithObjTypeSuffix += ".lthumb.jpg"
				
			#
			# build download history description, which is used both to check if we've already
			# downloaded the file (to optionally skip it) and also to write the history for
			# this file if we do download it. to uniquely identify the file we use a combination
			# of the filename, capture date, and size - these three elements togethre should
			# prevent us from any false positives/negatives for future images. note that for
			# filename we use the original name with the appended sthumb/lthumb suffix if we'read
			# downloading thumbs - that way we can uniquely track the downloading of the thumbs vs
			# the actual image/video file. see the comments for loadDownloadHistory() for
			# more information on how the history is handled
			#
			# format:
			# 	filenameWithObjTypeSuffix::MTP capture data str::Size in human-readable comma form::::current time str::outputDirPathAbsolute
			# example:
			#   DSC_0094.NEF::20150804T120900::22,719,774:::05/05/15 13:44::c:\pics
			#
			currentTimeStr = time.strftime("%m/%d/%y %H:%M:%S", time.localtime())
			downloadHistoryDescStr_Key = "{:s}::{:s}::{:,}".format(filenameWithObjTypeSuffix, mtpObject.mtpObjectInfo.captureDateStr, mtpObject.mtpObjectInfo.objectCompressedSize)
			downloadHistoryDescStr_Info = "{:s}::{:s}\n".format(currentTimeStr, outputDirPathAbsolute)							
			downloadHistoryDescStr_Full = downloadHistoryDescStr_Key + "::::" + downloadHistoryDescStr_Info
			if bSkipDownloadedFiles and downloadHistoryDict and (downloadHistoryDescStr_Key in downloadHistoryDict):
				#
				# this file is in history. put the 'additional info area' into a named tuple for clarity and then
				# log the information so the user knows the file has been skipped and when and where it was originally
				# downloaded. note that a file may have been previously  downloaded multiple times, which is possible
				# if the user instructed us to ignore history on one of those sessions - we only write the history on
				# the first/original download, thus the history reflects that instead a more recent re-download
				#
				DownloadHistoryElement = namedtuple('DownloadHistoryElement', 'dateDownloadedStr pathDownloadedToStr')
				listDownloadHistory = str.split(downloadHistoryDict[downloadHistoryDescStr_Key], '::') # each field of the additional info area is separated by two colons
				downloadHistoryElementTuple = DownloadHistoryElement(listDownloadHistory[0], listDownloadHistory[1])				
				applog_v("Skipping \"{:s}\" - downloaded on {:s} to \"{:s}\" ".\
					format(filenameWithObjTypeSuffix, downloadHistoryElementTuple.dateDownloadedStr, downloadHistoryElementTuple.pathDownloadedToStr))
				g.dlstat_countFilesSkippedDueToDownloadHistory += 1
				continue
				
			#
			# check if the output file already exists (if this isn't a file we're resuming a
			# failed download on)
			#
			if mtpObject.partialDownloadObj().getLocalFilenameWithoutPath() == None:
				localFilenameWithoutPath = filenameWithObjTypeSuffix
				localFilenameWithPath = os.path.join(addCameraFolderToPath_CreateDirIfNecessary(outputDirPathAbsolute, mtpObject), localFilenameWithoutPath)
				if (os.path.exists(localFilenameWithPath)):
					if g.args['ifexists'] == 'prompt':
						applog_i("\"{:s}\" exists".format(localFilenameWithPath))
						keyResponse = promptWithSingleKeyResponse("(S)kip, (O)verwrite, (U)niquename, (E)xit [+enter]: ", 'soue')
					else:
						keyResponse = ''			
					if g.args['ifexists'] == 'skip' or keyResponse == 'S':
						if not keyResponse:
							applog_i("Skipping \"{:s}\" - file exists".format(localFilenameWithPath))
						g.dlstat_countFilesSkippedDueToFileExistingLocally += 1
						continue
					elif g.args['ifexists'] == 'overwrite' or keyResponse == 'O':
						if not keyResponse:
							applog_v("\"{:s}\" exists - will be overwritten".format(localFilenameWithPath))
						applog_d("{:s} - deleting existing file per user config".format(localFilenameWithPath))
						os.remove(localFilenameWithPath)
					elif g.args['ifexists'] == 'uniquename' or keyResponse == 'U':
						uniqueFilenameWithPath = generateUniqueFilename(localFilenameWithPath)
						uniqueFilenameWithoutPath = os.path.basename(uniqueFilenameWithPath)
						if not keyResponse:
							applog_v("\"{:s}\" exists - will write to \"{:s}\"".format(localFilenameWithPath, uniqueFilenameWithoutPath))
						localFilenameWithPath = uniqueFilenameWithPath
						localFilenameWithoutPath = uniqueFilenameWithoutPath
						# note we don't want to change 'downloadHistoryDescStr_Full', as that is camera-filename relative
					elif g.args['ifexists'] == 'exit' or keyResponse == 'E':
						applog_i("\"{:s}\" exists - exiting per user config".format(localFilenameWithPath))
						sys.exit(ERRNO_FILE_EXISTS_USER_SPECIFIED_EXIT)
				#
				# save the local filename in case we had to generate a unique name and the
				# transfer fails this invocation (we'll need the potentially unique filename
				# on the retry invocation)
				#
				mtpObject.partialDownloadObj().setLocalFilenameWithoutPath(localFilenameWithoutPath)
						
			else:
				#
				# this is a retry of a failed transfer and we generated the
				# local filename when the transfer was started. we need to use
				# that originally generated name in case it involved creating
				# a unique filename due to an pre-existing local file
				#
				localFilenameWithoutPath = mtpObject.partialDownloadObj().getLocalFilenameWithoutPath()				
				localFilenameWithPath = os.path.join(addCameraFolderToPath_CreateDirIfNecessary(outputDirPathAbsolute, mtpObject), localFilenameWithoutPath)			
						
			# notify camera of acquisition start for this object if it was selected by the user in the camera (in camera transfer list)
			if g.bReceivedTransferListFromCamera:
				mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_NotifyFileAcquisitionStart, struct.pack('<I', mtpObject.mtpObjectHandle))
			
			# get the object
			applog_d(">> {:s}".format(getMtpOpDesc(mtpOpGet)))
			
			consoleWriteLine("Downloading \"{:s}\":  0%".format(localFilenameWithoutPath))

			#
			# do the get/download
			#			
			bUsingGetPartialObject = (mtpOpGet == MTP_OP_GetObject) # as opposed to MTP_OP_GetThumb or MTP_OP_GetLargeThumb
			foDownloadedFile = None # no (new) data written to file yet this invocation
			if bUsingGetPartialObject:
				
				try:

					#
					# we may have already written some of the file on a previous invocation. if
					# so it will be reflected in the partialDownloadObj()
					# 
					fileSizeBytes = mtpObject.mtpObjectInfo.objectCompressedSize
					bytesWritten = mtpObject.partialDownloadObj().getBytesWritten()
		
					if bytesWritten > 0:
						#
						# as a data integrity safeguard, make sure the size of the file is equal to
						# the number of bytes we think we've written
						#
						applog_d("{:s} - resuming download - bytesWritten=0x{:x}, fileSize=0x{:x}".format(localFilenameWithoutPath, bytesWritten, fileSizeBytes))
						if (os.path.exists(localFilenameWithPath + ".part")):
							statInfo = os.stat(localFilenameWithPath + ".part")
							if statInfo.st_size != bytesWritten:									
								raise AssertionError("About to resume download for \"{:s}\" but it's filesize is not equal the how much data we've already downloaded and written (expected 0x{:x}, actual 0x{:x}".format(localFilenameWithoutPath, bytesWritten, statInfo.st_size))
						else:
							raise AssertionError("About to resume download for \"{:s}\" but the file is missing. It should be present and have a size of 0x{:x}".format(localFilenameWithoutPath, bytesWritten))									

							
					#
					# note there's a corner case where bytesWritten can already
					# be equal to fileSizeBytes. this can happen if there was a
					# communication error on the previous invocation after we
					# received the final data payload but during the cmd response
					# phase. the logic below is designed to gracefully handle this case
					#

					#
					# loop to download and write each piece of the object. the size of each
					# transfer is constrained by g.maxGetObjTransferSize
					#
					offsetIntoImage = bytesWritten
					dataReceived = six.binary_type()
					while offsetIntoImage < fileSizeBytes:
						bytesToDownloadThisPiece = min(g.maxGetObjTransferSize, fileSizeBytes-offsetIntoImage)
						if len(dataReceived)+bytesToDownloadThisPiece > g.maxGetObjBufferSize:
							# the amount of data we already have + size of this transfer would exceed our configure maxgetobjbuffersize - constrain it
							bytesToDownloadThisPiece -= (len(dataReceived)+bytesToDownloadThisPiece) - g.maxGetObjBufferSize
						if bytesToDownloadThisPiece == 0:
							# shouldn't happen
							raise AssertionError("bytesToDownloadThisPiece is zero! offset=0x{:x}, fileSize=0x{:x}, dataReceived=0x{:x}, max=0x{:x}/0x{:x}".format(\
								offsetIntoImage, fileSizeBytes, len(dataReceived), g.maxGetObjTransferSize, g.maxGetObjBufferSize))
						applog_d("{:s} - downloading next piece, offset=0x{:x}, count=0x{:x}".format(localFilenameWithoutPath, offsetIntoImage, bytesToDownloadThisPiece))
						timeStart = time.time()
						mtpTcpCmdResultGetObj = mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_GetPartialObject, struct.pack('<III',\
							mtpObject.mtpObjectHandle, offsetIntoImage, bytesToDownloadThisPiece),\
							rxTxProgressFunc=lambda bytesReceivedAllCurrentPayloads, totalBytesExpectedAllCurrentPayloads :\
							processMtpObjects_DownloadProgressCallback(bytesReceivedAllCurrentPayloads, totalBytesExpectedAllCurrentPayloads, offsetIntoImage, fileSizeBytes))
						mtpObject.partialDownloadObj().addDownloadTimeSecs(time.time() - timeStart)
													
						dataReceived += mtpTcpCmdResultGetObj.dataReceived				
						offsetIntoImage += bytesToDownloadThisPiece

						# update progress indication to user
						processMtpObjects_DownloadProgressCallback(0, 0, offsetIntoImage, fileSizeBytes)
						
						bIsFinalPiece = (offsetIntoImage == fileSizeBytes)
						if bIsFinalPiece or len(dataReceived) >= g.maxGetObjBufferSize:
							# we've reached/exceeded our max buffer size or this is the final piece. write out the data we have
							foDownloadedFile = writeDataToDownloadedFile(foDownloadedFile, localFilenameWithPath, dataReceived, bIsFinalPiece, (bytesWritten != 0)) # close file if this is the last piece
							mtpObject.partialDownloadObj().addBytesWritten(len(dataReceived))
							bytesWritten += len(dataReceived)
							dataReceived = six.binary_type()						

					#
					# we've completed the download and writing of the file
					#
					fileDownloadTimeSecs = mtpObject.partialDownloadObj().getDownloadTimeSecs()
						
				except mtpwifi.MtpOpExecFailureException as e:
					mtpObject.partialDownloadObj().addDownloadTimeSecs(time.time() - timeStart)
					applog_i("") # newline since console is on "Downloading ...." message
					applog_d("{:s} - error during download, writing 0x{:x} bytes of buffered data".format(localFilenameWithoutPath, len(dataReceived)))
					
					# flush out any unwritten data we have in 'dataReceived'
					if dataReceived:
						foDownloadedFile = writeDataToDownloadedFile(foDownloadedFile, localFilenameWithPath, dataReceived, False, (bytesWritten != 0))
						bytesWritten += len(dataReceived)
						mtpObject.partialDownloadObj().addBytesWritten(len(dataReceived))
					if e.partialData:
						#
						# more data was received before the communication failure. write
						# that partial data to the file so that we don't have to incur the
						# performance penalty of re-downloading it on the next retry invocation
						# 
						applog_d("{:s} - writing partial payload data of 0x{:x} bytes".format(localFilenameWithoutPath, len(e.partialData)))
						foDownloadedFile = writeDataToDownloadedFile(foDownloadedFile, localFilenameWithPath, e.partialData, False, (bytesWritten != 0))
						bytesWritten += len(e.partialData)
						mtpObject.partialDownloadObj().addBytesWritten(len(e.partialData))
					if foDownloadedFile:
						foDownloadedFile.close()
					raise
						
			else: # else of if bUsingGetPartialObject

				timeStart = time.time()
				mtpTcpCmdResultGetObj = mtpwifi.execMtpOp(g.socketPrimary, mtpOpGet, struct.pack('<I', mtpObject.mtpObjectHandle),\
					rxTxProgressFunc=lambda bytesReceivedAllCurrentPayloads, totalBytesExpectedAllCurrentPayloads : processMtpObjects_DownloadProgressCallback(bytesReceivedAllCurrentPayloads, totalBytesExpectedAllCurrentPayloads, 0, 0))
				dataReceived = mtpTcpCmdResultGetObj.dataReceived
				fileDownloadTimeSecs = time.time() - timeStart
				fileSizeBytes = len(dataReceived)
				writeDataToDownloadedFile(foDownloadedFile, localFilenameWithPath, dataReceived, True, False)

			#
			# this completion path is common for both the get-object case and the small/large thumb case
			# both paths are required to have these vars set:
			#
			#		fileDownloadTimeSecs - total download time of file
			#		fileSizeBytes - size of file
			#
			# now write data to file. for the get-object case this will be the last piece of
			# data received for the file (after zero or more other pieces have already
			# been written). for the small/large thumb case this will always been the
			# only piece of data for the file
			#
			consoleClearLine()	# erase "Downloading..." status line
										
			#
			# mark the file as downloaded. this means any exception that occurs
			# in logic after marking the download complete wont trigger a re-download
			# on a subsequent invocation of this routine. as such, be careful where
			# any future logic is place relative to this sentinel
			#
			mtpObject.setAsDownloadedThisSession()
			mtpObject.releasePartialDownloadObj()
			os.rename(localFilenameWithPath + ".part", localFilenameWithPath) # download done - safe to rename to final filename
			g.filesToDeleteOnAppExit.remove(localFilenameWithPath + ".part")
			
			#
			# print download completion message with transfer rate calculation
			#
			if fileDownloadTimeSecs > 0: # avoid divide-by-zero, though not expecting ever expecting 'fileDownloadTimeSecs' to be zero
				thisFileDownloadRateMbSec = fileSizeBytes / fileDownloadTimeSecs / 1048576
			else:
				thisFileDownloadRateMbSec = 0
			applog_i("{:s} [size = {:,}] in {:.2f} seconds ({:.2f} MB/s)".format(localFilenameWithPath,\
				fileSizeBytes, fileDownloadTimeSecs, thisFileDownloadRateMbSec))
									
			#
			# update running stats and mark the file as downloaded
			#
			g.dlstat_totalDownloadTimeSecs += fileDownloadTimeSecs
			g.dlstat_totalBytesDownloaded += fileSizeBytes
			g.dlstat_countFilesDownloaded += 1			


			#
			# notify camera of acquisition end for this object if it was selected by the user in the camera (in camera transfer list).
			# this action removes the image/file from the transfer list in the camera
			#
			if g.bReceivedTransferListFromCamera:
				mtpwifi.execMtpOp(g.socketPrimary, MTP_OP_NotifyFileAcquisitionEnd, struct.pack('<I', mtpObject.mtpObjectHandle))

			#
			# add this file to the download history file. note that we don't need to add
			# the file to our in-memory downloadHistoryDict since we wont be attempting
			# a download of this file during this session. also note when
			# bSkipDownloadedFiles==FALSE (user specified to ignore download history and
			# force download), there may already be an entry in the history file for
			# this image - to prevent duplicates we check membership first
			#
			if not downloadHistoryDict or (downloadHistoryDescStr_Key not in downloadHistoryDict):
				# if there's either no previous history or this file is not already in the history
				fileDownloadHistory.write(downloadHistoryDescStr_Full)
				fileDownloadHistory.flush()			
									
			#
			# set the file's last modification+access time to the original creation
			# time reported that the camera reported for this object, which is the
			# behavior the user gets when he transfers images off the camera or media
			# card directly. note that we're doing this *after* we've marked the download
			# complete - the call to os.utime() is not critical in terms of retrying it,
			# so we still want to consider the download/file complete even if this call fails
			#
			os.utime(localFilenameWithPath, (mtpObject.captureDateEpoch, mtpObject.captureDateEpoch))


	# do any post-operation cleanup
	if bActionIsDownload:
		fileDownloadHistory.close()
		
	# do post-operation reporting
	if bActionIsDownload:
		if g.dlstat_totalDownloadTimeSecs > 0: # avoid divide-by-zero in case no files downloaded
			averageDownloadRateMbSec = g.dlstat_totalBytesDownloaded / g.dlstat_totalDownloadTimeSecs / 1048576
		else:
			averageDownloadRateMbSec = 0
		applog_i("\n{:d} files downloaded in {:.2f} seconds (Average Rate = {:.2f} MB/s)".format(g.dlstat_countFilesDownloaded, g.dlstat_totalDownloadTimeSecs, averageDownloadRateMbSec))
		if g.dlstat_countFilesSkippedDueToDownloadHistory:
			applog_i("{:d} previously-downloaded files skipped".format(g.dlstat_countFilesSkippedDueToDownloadHistory))
		if g.dlstat_countFilesSkippedDueToFileExistingLocally:
			applog_i("{:d} files skipped because they already existed in output directory".format(g.dlstat_countFilesSkippedDueToFileExistingLocally))
	elif g.args['action'] == 'listfiles':
		applog_i("        {:4d} File(s)  {:13,} bytes".format(countFilesListed, totalBytesOfImagesInObjectsListed))
		applog_i("        {:4d} Dir(s)  {:13,} bytes free".format(countDirectories, g.MtpStorageInfo.freeSpaceBytes))
		

#
# main work routine
#
def appMain():

	bAttemptCloseSessionAtTermination = False		
	try:
		#
		# start wireless session
		#
		startMtpSession()
		bAttemptCloseSessionAtTermination = True	# we're now in a session, so set flag to close it when we're done

		#
		# get camera (device) info
		#
		getMtpDeviceInfo()
							
		#
		# select appropriate media card slot (storage ID)
		#
		selectMtpStorageId()
		
		#
		# get information on media card
		#
		getMtpStorageInfo()
		
		#
		# populate our list of MTP objects. we bypass this if we've retrieved all objects
		# on a previous retry this session. this is done only to avoid the extra user
		# messages from objects that we already have
		#
		if g.bRetrievedMtpObjects == False:
			buildMtpObjects()
			g.bRetrievedMtpObjects = True

			
		#
		# process objects
		#	
		processMtpObjects()
		
		#
		# successful completion
		#
		return (0, False)
		
	except mtpwifi.MtpOpExecFailureException as e:
		applog_e(str(e))
		if g.args['printstackframes'] == 'yes':
			applog_e(traceback.format_exc())				
		if e.mtpRespCode == MTP_RESP_COMMUNICATION_ERROR:
			bAttemptCloseSessionAtTermination = False	# since there was a communication error, no sense in attempting to close the MTP session (wastes time, will likely fail anyway)
			return (ERRNO_CAMERA_COMMUNICATION_FAILURE, True)
		else:
			return (ERRNO_CAMERA_UNEXPECTED_RESP_CODE, False) # don't retry on a high-level MTP error - we're trying to do something the camera doesn't like
	except mtpwifi.MtpProtocolException as e:
		applog_e(str(e))
		if g.args['printstackframes'] == 'yes':
			applog_e(traceback.format_exc())
		bAttemptCloseSessionAtTermination = False	# since there was a communication error, no sense in attempting to close the MTP session (wastes time, will likely fail anyway)
		return (ERRNO_CAMERA_PROTOCOL_ERROR, True)
	except socket.error as e:
		applog_e("Socket Error: " + str(e))
		if g.args['printstackframes'] == 'yes':
			applog_e(traceback.format_exc())
		bAttemptCloseSessionAtTermination = False	# since there was a communication error, no sense in attempting to close the MTP session (wastes time, will likely fail anyway)		
		if e.errno != 0: # make sure we're returning a non-zero exit code (not all socket exceptions can be relied on to do so)
			return (e.errno, True)
		else:
			# socket.timeout doesn't define errno. use errno.ETIMEDOUT. also in case the
			# other socket excpetions don't place an errno either
			return (errno.ETIMEDOUT, True)
	except IOError as e:
		applog_e("IOError: " + str(e))
		if g.args['printstackframes'] == 'yes':
			applog_e(traceback.format_exc())
		return (e.errno, False)
	except KeyboardInterrupt as e:
		applog_e("\n>> Terminated by user keypress <<")
		if g.args['printstackframes'] == 'yes':
			applog_e(traceback.format_exc())			
		return (errno.EINTR, False)
	except SystemExit as e:
		#
		# someone called sys.exit(). we use sys.exit() for cases where the
		# error condition was captured by higher-level code and a user message
		# generated, thus to avoid printing an exception by this routine.
		# we can still retry these conditions - it depends on whether the caller
		# selected an errno within the "don't retry" range
		#
		if g.args['printstackframes'] == 'yes':
			applog_e(traceback.format_exc())			
		return (e.code, e.code < ERRNO_FIRST_CUSTOM_DONT_RETRY or  e.code > ERRNO_LAST_CUSTOM_DONT_RETRY)
	except: # capture remainder of exceptions, in particular syntax/programming exceptions
		applog_e("An exception occurred. Here is the stack trace information:\n" + traceback.format_exc()) # we always print stack frames for programming errors ('printstackframes' is  ignored)
		return (errno.EFAULT, False)
			
	finally:
		if bAttemptCloseSessionAtTermination:
			#
			# end MTP session (MTP_OP_CloseSession). We avoid doing this if we got here from
			# a communication error, since the MTP_OP_CloseSession would likely fail
			# anyway and just take up extra time. However even if a communication error
			# didn't occur there are other situations where the MTP_OP_CloseSession we're about
			# to send might be expected to fail, such as if we were in the middle of an MTP
			# command when the user quit via KeyboardInterrupt. For this reason we squelch
			# any errors/exceptions that might occur during MTP_OP_CloseSession, only reporting
			# the exception to the debug log
			#
			try:
				endMtpSession()
			except:
				applog_d("Exception during endMtpSession()")
				applog_d(traceback.format_exc())		
		closeSockets()
			
			
#
# deletes all files marked for deletion upon exit. this mechanism is necessary to
# delete a file we were downloading/writing but failed before the operation could
# completed. we don't want to leave a partially written file, otherwise the user
# might think it's a valid file
#
def deleteFilesMarkedForDeletionOnExit():
	for filenameWithPath in g.filesToDeleteOnAppExit:
		applog_d("deleteFilesMarkedForDeletionOnExit(): Processing {:s}".format(filenameWithPath))
		try: # ignore os.path.exists() errors
			if (os.path.exists(filenameWithPath)):
				applog_v("Deleting \"{:s}\" because of a failed download or file operation".format(filenameWithPath))
				deleteFileIgnoreErrors(filenameWithPath)
		except:
			pass

		
#
# main app routine
#			
def main():	

	#
	# establish our app environment, including our app-specific subdirectories
	#
	establishAppEnvironment()
	
	#
	# init applog, to allow logging of output to log files
	#
	_errno = applog_init(APPLOGF_LEVEL_INFORMATIONAL | APPLOGF_LEVEL_ERROR, os.path.join(g.appDataDir, "airnefcmd-log-last.txt"),\
		os.path.join(g.appDataDir, "airnefcmd-log-lifetime.txt"))
	if _errno:
		sys.exit(_errno)
	
	#
	# display app banner
	#
	applog_i("\nairnef v{:s} - Wireless transfer of images/movies for Nikon cameras [GPL v3]".format(AIRNEFCMD_APP_VERSION))
	applog_i("Copyright (c) TestCams.com, App Launch Time: {:s}\n".format(time.ctime()))
	
	#
	# verify we're running under a tested version of python
	#
	verifyPythonVersion()	
	
	#
	# process command line arguments
	#
	processCmdLine()
		
	#
	# do app's main work
	#
	attemptNumber = 0
	while True:	
		try:
		
			(_errno, retryRecommended) = appMain()
			if retryRecommended == False:
				# if successful or if user terminated app
				break;
				
			attemptNumber += 1
			if attemptNumber >= g.args['retrycount']:
				applog_i("\nNumber of attempts ({:d}) has reached maximum configured value - exiting".format(attemptNumber))
				break;
				
			applog_i("\nDelaying {:d} seconds before trying again. Press <ctrl-c> to exit [{:d} attempts]\n".format(g.args['retrydelaysecs'], attemptNumber))
			time.sleep(g.args['retrydelaysecs'])
			
		except KeyboardInterrupt as e: # in case <ctrl>-c is pressed in delay above
			try: 
				applog_e("\n>> Terminated by user keypress <<")
				_errno = errno.EINTR
			except KeyboardInterrupt as e:
				# for some reason we intermittently get a second SIGINT running on Linux frozen; ignore the 2nd
				pass
			break;

	#
	# cleanup and then exit
	#
	deleteFilesMarkedForDeletionOnExit()
	applog_i(">>>> airnefcmd session over - App Exit Time: {:s}".format(time.ctime())) # used by utils to see if we exited gracefully
	applog_shutdown()
	return _errno

#
# program entry point
#	
if __name__ == "__main__":
	_errno = main()
	sys.exit(_errno)
